{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5fcca3-47b0-4d38-bb8c-3b8120cb6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices3x3 = {\n",
    "    'mat_3x3_00': [\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 0]\n",
    "    ],\n",
    "    'mat_3x3_01': [\n",
    "        [255, 255, 255],\n",
    "        [255, 255, 255],\n",
    "        [255, 255, 255]\n",
    "    ],\n",
    "    'mat_3x3_02': [\n",
    "        [0, 255, 255],\n",
    "        [255, 255, 255],\n",
    "        [255, 255, 255]\n",
    "    ],\n",
    "    'mat_3x3_00': [\n",
    "        [255, 0, 0],\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 0]\n",
    "    ],\n",
    "    'mat_3x3_01': [\n",
    "        [255, 255, 255],\n",
    "        [255, 255, 255],\n",
    "        [255, 255, 0]\n",
    "    ],\n",
    "    'mat_3x3_00': [\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 255]\n",
    "    ],\n",
    "    'mat_3x3_11': [\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 0],\n",
    "        [255, 255, 255]\n",
    "    ],\n",
    "    'mat_3x3_12': [\n",
    "        [255, 255, 255],\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 0]\n",
    "    ],\n",
    "    'mat_3x3_13': [\n",
    "        [255, 255, 255],\n",
    "        [255, 255, 255],\n",
    "        [0, 0, 0]\n",
    "    ],\n",
    "    'mat_3x3_14': [\n",
    "        [0, 0, 0],\n",
    "        [255, 255, 255],\n",
    "        [255, 255, 255]\n",
    "    ],\n",
    "    'mat_3x3_21': [\n",
    "        [255, 255, 0],\n",
    "        [255, 0, 0],\n",
    "        [0, 0, 0]\n",
    "    ],\n",
    "    'mat_3x3_22': [\n",
    "        [0, 0, 255],\n",
    "        [0, 255, 255],\n",
    "        [255, 255, 255]\n",
    "    ],\n",
    "    'mat_3x3_23': [\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 255],\n",
    "        [0, 255, 255]\n",
    "    ],\n",
    "    'mat_3x3_24': [\n",
    "        [255, 255, 255],\n",
    "        [255, 255, 0],\n",
    "        [255, 0, 0]\n",
    "    ],\n",
    "    'mat_3x3_31': [\n",
    "        [255, 0, 0],\n",
    "        [255, 0, 0],\n",
    "        [255, 0, 0]\n",
    "    ],\n",
    "    'mat_3x3_32': [\n",
    "        [0, 0, 255],\n",
    "        [0, 0, 255],\n",
    "        [0, 0, 255]\n",
    "    ],\n",
    "    'mat_3x3_33': [\n",
    "        [0, 255, 255],\n",
    "        [0, 255, 255],\n",
    "        [0, 255, 255]\n",
    "    ],\n",
    "    'mat_3x3_34': [\n",
    "        [255, 255, 0],\n",
    "        [255, 255, 0],\n",
    "        [255, 255, 0]\n",
    "    ],\n",
    "    'mat_3x3_41': [\n",
    "        [255, 0,   0],\n",
    "        [255, 255, 0],\n",
    "        [255, 255, 255]\n",
    "    ],\n",
    "    'mat_3x3_42': [\n",
    "        [0, 255, 255],\n",
    "        [0, 0,   255],\n",
    "        [0, 0,   0]\n",
    "    ],\n",
    "    'mat_3x3_43': [\n",
    "        [255, 255, 255],\n",
    "        [0, 255, 255],\n",
    "        [0, 0, 255]\n",
    "    ],\n",
    "    'mat_3x3_44': [\n",
    "        [0, 0, 0],\n",
    "        [255, 0, 0],\n",
    "        [255, 255, 0]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe76fd4-82f8-42d8-9c98-313f6c8123f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices5x5 = {\n",
    "    'mat_5x5_00': [\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_5x5_01': [\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_5x5_11': [\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_5x5_12': [\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_5x5_13': [\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_5x5_14': [\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_5x5_21': [\n",
    "        [0, 0, 0, 0, 255],\n",
    "        [0, 0, 0, 255, 255],\n",
    "        [0, 0, 255, 255, 255],\n",
    "        [0, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_5x5_22': [\n",
    "        [255, 255, 255, 255, 0],\n",
    "        [255, 255, 255, 0, 0],\n",
    "        [255, 255, 0, 0, 0],\n",
    "        [255, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_5x5_23': [\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 255],\n",
    "        [0, 0, 0, 255, 255],\n",
    "        [0, 0, 255, 255, 255],\n",
    "        [0, 255, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_5x5_24': [\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 0],\n",
    "        [255, 255, 255, 0, 0],\n",
    "        [255, 255, 0, 0, 0],\n",
    "        [255, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_5x5_31': [\n",
    "        [0, 0, 0, 255, 255],\n",
    "        [0, 0, 0, 255, 255],\n",
    "        [0, 0, 0, 255, 255],\n",
    "        [0, 0, 0, 255, 255],\n",
    "        [0, 0, 0, 255, 255]\n",
    "    ],\n",
    "    'mat_5x5_32': [\n",
    "        [255, 255, 255, 0, 0],\n",
    "        [255, 255, 255, 0, 0],\n",
    "        [255, 255, 255, 0, 0],\n",
    "        [255, 255, 255, 0, 0],\n",
    "        [255, 255, 255, 0, 0]\n",
    "    ],\n",
    "    'mat_5x5_33': [\n",
    "        [0, 0, 255, 255, 255],\n",
    "        [0, 0, 255, 255, 255],\n",
    "        [0, 0, 255, 255, 255],\n",
    "        [0, 0, 255, 255, 255],\n",
    "        [0, 0, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_5x5_34': [\n",
    "        [255, 255, 0, 0, 0],\n",
    "        [255, 255, 0, 0, 0],\n",
    "        [255, 255, 0, 0, 0],\n",
    "        [255, 255, 0, 0, 0],\n",
    "        [255, 255, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_5x5_41': [\n",
    "        [255, 0, 0, 0, 0],\n",
    "        [255, 255, 0, 0, 0],\n",
    "        [255, 255, 255, 0, 0],\n",
    "        [255, 255, 255, 255, 0],\n",
    "        [255, 255, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_5x5_42': [\n",
    "        [0, 255, 255, 255, 255],\n",
    "        [0, 0, 255, 255, 255],\n",
    "        [0, 0, 0, 255, 255],\n",
    "        [0, 0, 0, 0, 255],\n",
    "        [0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_5x5_43': [\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [255, 0, 0, 0, 0],\n",
    "        [255, 255, 0, 0, 0],\n",
    "        [255, 255, 255, 0, 0],\n",
    "        [255, 255, 255, 255, 0]\n",
    "    ],\n",
    "    'mat_5x5_44': [\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [0, 255, 255, 255, 255],\n",
    "        [0, 0, 255, 255, 255],\n",
    "        [0, 0, 0, 255, 255],\n",
    "        [0, 0, 0, 0, 255]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b647f38c-8015-4008-9612-ec740623051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices7x7 = {\n",
    "    'mat_7x7_00': [\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_7x7_01': [\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_7x7_11': [\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_7x7_12': [\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_7x7_13': [\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_7x7_14': [\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_7x7_21': [\n",
    "        [0, 0, 0, 0, 0, 0, 255],\n",
    "        [0, 0, 0, 0, 0, 255, 255],\n",
    "        [0, 0, 0, 0, 255, 255, 255],\n",
    "        [0, 0, 0, 255, 255, 255, 255],\n",
    "        [0, 0, 255, 255, 255, 255, 255],\n",
    "        [0, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_7x7_22': [\n",
    "        [255, 255, 255, 255, 255, 255, 0],\n",
    "        [255, 255, 255, 255, 255, 0, 0],\n",
    "        [255, 255, 255, 255, 0, 0, 0],\n",
    "        [255, 255, 255, 0, 0, 0, 0],\n",
    "        [255, 255, 0, 0, 0, 0, 0],\n",
    "        [255, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_7x7_23': [\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 255],\n",
    "        [0, 0, 0, 0, 0, 255, 255],\n",
    "        [0, 0, 0, 0, 255, 255, 255],\n",
    "        [0, 0, 0, 255, 255, 255, 255],\n",
    "        [0, 0, 255, 255, 255, 255, 255],\n",
    "        [0, 255, 255, 255, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_7x7_24': [\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [255, 255, 255, 255, 255, 255, 0],\n",
    "        [255, 255, 255, 255, 255, 0, 0],\n",
    "        [255, 255, 255, 255, 0, 0, 0],\n",
    "        [255, 255, 255, 0, 0, 0, 0],\n",
    "        [255, 255, 0, 0, 0, 0, 0],\n",
    "        [255, 0, 0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_7x7_31': [\n",
    "        [0, 0, 0, 0, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_7x7_32': [\n",
    "        [255, 255, 255, 255, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_7x7_33': [\n",
    "        [0, 0, 0, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 255, 255, 255, 255]\n",
    "    ],\n",
    "    'mat_7x7_34': [\n",
    "        [255, 255, 255, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'mat_7x7_41': [\n",
    "        [255, 0, 0, 0, 0, 0, 0],\n",
    "        [255, 255, 0, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 255, 0, 0],\n",
    "        [255, 255, 255, 255, 255, 255, 0],\n",
    "        [255, 255, 255, 255, 255, 255, 255]\n",
    "    ],\n",
    "\n",
    "    'mat_7x7_42': [\n",
    "        [0, 255, 255, 255, 255, 255, 255],\n",
    "        [0, 0, 255, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 0, 255, 255],\n",
    "        [0, 0, 0, 0, 0, 0, 255],\n",
    "        [0, 0, 0, 0, 0, 0, 0]\n",
    "    ],\n",
    "\n",
    "    'mat_7x7_43': [\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [255, 0, 0, 0, 0, 0, 0],\n",
    "        [255, 255, 0, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 0, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 0, 0, 0],\n",
    "        [255, 255, 255, 255, 255, 0, 0],\n",
    "        [255, 255, 255, 255, 255, 255, 0]\n",
    "    ],\n",
    "\n",
    "    'mat_7x7_44': [\n",
    "        [255, 255, 255, 255, 255, 255, 255],\n",
    "        [0, 255, 255, 255, 255, 255, 255],\n",
    "        [0, 0, 255, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 255, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 255, 255, 255],\n",
    "        [0, 0, 0, 0, 0, 255, 255],\n",
    "        [0, 0, 0, 0, 0, 0, 255]\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3007d313-a188-461e-8e0e-1fe171cf24a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to add random noise to a matrix\n",
    "def add_noise(matrix, mean=0, std_dev=30):\n",
    "    gaussian_noise = np.random.normal(mean, std_dev, matrix.shape)\n",
    "    noisy_matrix = matrix + gaussian_noise\n",
    "    noisy_matrix = np.clip(noisy_matrix, 0, 255)  # Ensure values are within [0, 255]\n",
    "    return noisy_matrix\n",
    "\n",
    "#function to generate csv file for the matrices\n",
    "def generate_csv(matrices, mean, std_dev_start, std_dev_end, step, num_iterations, filename):\n",
    "    data = []\n",
    "\n",
    "    for matrix_name, matrix in matrices.items():\n",
    "        base_matrix = np.array(matrix)\n",
    "        first_digit = int(matrix_name[-2])\n",
    "        second_digit = int(matrix_name[-1])\n",
    "        size = len(matrix[0])\n",
    "        for std_dev in range(std_dev_start, std_dev_end, step):\n",
    "            for _ in range(num_iterations):\n",
    "                # Add random noise\n",
    "                noisy_matrix = add_noise(base_matrix, mean, std_dev)\n",
    "                #normalise the matrix\n",
    "                noisy_matrix = noisy_matrix/255.0\n",
    "                # Flatten the matrix to store as a row\n",
    "                noisy_matrix_flat = noisy_matrix.flatten()\n",
    "        \n",
    "                if first_digit == 0:\n",
    "                    edge_detected = 0\n",
    "                else:\n",
    "                    edge_detected = 1\n",
    "                \n",
    "                # Append the flattened matrix and labels to the data list\n",
    "                data.append(list(noisy_matrix_flat) + [edge_detected, first_digit, second_digit])\n",
    "    \n",
    "    # Convert the data to a DataFrame and save to CSV\n",
    "    columns = [f'pixel_{i}' for i in range(size*size)] + ['edge_detected', 'first_digit', 'second_digit']\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    print(\"CSV file generated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2de3a9-e84c-4300-98d8-91540dc351e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file generated successfully.\n"
     ]
    }
   ],
   "source": [
    "matrices = matrices3x3\n",
    "mean = 0\n",
    "std_dev_start = 20\n",
    "std_dev_end = 61\n",
    "step = 10\n",
    "num_iterations = 2000\n",
    "filename = 'C:\\Ankit\\Programs\\RP\\data\\\\train\\mat_3x3.csv'\n",
    "generate_csv(matrices, mean, std_dev_start, std_dev_end, step, num_iterations, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25a457fe-b64a-4d21-bd02-7cb519dcdf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file generated successfully.\n"
     ]
    }
   ],
   "source": [
    "matrices = matrices5x5\n",
    "mean = 0\n",
    "std_dev_start = 20\n",
    "std_dev_end = 61\n",
    "step = 10\n",
    "num_iterations = 2000\n",
    "filename = 'C:\\Ankit\\Programs\\RP\\data\\\\train\\mat_5x5.csv'\n",
    "generate_csv(matrices, mean, std_dev_start, std_dev_end, step, num_iterations, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb1cf7df-a170-4006-b1b0-8846991c6f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file generated successfully.\n"
     ]
    }
   ],
   "source": [
    "matrices = matrices7x7\n",
    "mean = 0\n",
    "std_dev_start = 20\n",
    "std_dev_end = 61\n",
    "step = 10\n",
    "num_iterations = 2000\n",
    "filename = 'C:\\Ankit\\Programs\\RP\\data\\\\train\\mat_7x7.csv'\n",
    "generate_csv(matrices, mean, std_dev_start, std_dev_end, step, num_iterations, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34460de3-d787-4120-9690-62d0a022fb8f",
   "metadata": {},
   "source": [
    "## Training the nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8840851b-8d79-4eb9-ac78-8c413e7b15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Load data from file\n",
    "    data = np.loadtxt(file_path, delimiter=',', skiprows=1)\n",
    "    \n",
    "    # Extract features\n",
    "    X = data[:, :-3]  # All columns except the last three are features\n",
    "    \n",
    "    # Extract targets\n",
    "    y1 = data[:, -3]  # First output (binary: Yes/No)\n",
    "    y2 = data[:, -2]  # Second output (integer: 1–4)\n",
    "    y3 = data[:, -1]  # Third output (integer: 1–4)\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train1, y_test1, y_train2, y_test2, y_train3, y_test3 = train_test_split(\n",
    "        X, y1, y2, y3, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Combine outputs into dictionaries for easier handling\n",
    "    y_train = {'output1': y_train1, 'output2': y_train2, 'output3': y_train3}\n",
    "    y_test = {'output1': y_test1, 'output2': y_test2, 'output3': y_test3}\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def build_multi_output_model(input_size):\n",
    "    # Shared base\n",
    "    inputs = Input(shape=(input_size, 1))\n",
    "    x = Conv1D(8, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.001))(inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Branch 1: Binary classification (Yes/No)\n",
    "    branch1 = Dense(4, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    # branch1 = Dropout(0.2)(branch1)\n",
    "    output1 = Dense(1, activation='sigmoid', name='output1')(branch1)  # Sigmoid for binary output\n",
    "    \n",
    "    # Branch 2: Multiclass classification (1–4)\n",
    "    branch2 = Dense(4, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    # branch2 = Dropout(0.2)(branch2)\n",
    "    output2 = Dense(5, activation='softmax', name='output2')(branch2)  # Softmax for 4-class output\n",
    "    \n",
    "    # Branch 3: Multiclass classification (1–4)\n",
    "    branch3 = Dense(4, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    # branch3 = Dropout(0.2)(branch3)\n",
    "    output3 = Dense(5, activation='softmax', name='output3')(branch3)  # Softmax for 4-class output\n",
    "    \n",
    "    # Combine into a multi-output model\n",
    "    model = Model(inputs=inputs, outputs=[output1, output2, output3])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_multi_output_model(X_train, X_test, y_train, y_test, input_size):\n",
    "    # Reshape X data for Conv1D input\n",
    "    X_train = X_train.reshape(-1, input_size, 1)\n",
    "    X_test = X_test.reshape(-1, input_size, 1)\n",
    "\n",
    "    # Directly extract outputs from dictionaries\n",
    "    y1_train, y2_train, y3_train = y_train['output1'], y_train['output2'], y_train['output3']\n",
    "    y1_test, y2_test, y3_test = y_test['output1'], y_test['output2'], y_test['output3']\n",
    "\n",
    "    # Build the model\n",
    "    model = build_multi_output_model(input_size)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'output1': 'binary_crossentropy',\n",
    "            'output2': 'sparse_categorical_crossentropy',\n",
    "            'output3': 'sparse_categorical_crossentropy'\n",
    "        },\n",
    "        metrics={\n",
    "            'output1': ['accuracy'],\n",
    "            'output2': ['accuracy'],\n",
    "            'output3': ['accuracy']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        {'output1': y1_train, 'output2': y2_train, 'output3': y3_train},\n",
    "        epochs=50,\n",
    "        batch_size=128,\n",
    "        validation_split=0.3,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    model_name = f\"ed_{input_size}x{input_size}.keras\"\n",
    "    model.save(model_name)\n",
    "    print(f\"Model saved as {model_name}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    results = model.evaluate(X_test, {'output1': y1_test, 'output2': y2_test, 'output3': y3_test})\n",
    "    print(\"Test Results:\", results)\n",
    "\n",
    "    # Generate predictions\n",
    "    preds = model.predict(X_test)\n",
    "    y1_pred = (preds[0] > 0.5).astype(int)  # Binary predictions for output1\n",
    "    y2_pred = np.argmax(preds[1], axis=1)  # Multiclass predictions for output2\n",
    "    y3_pred = np.argmax(preds[2], axis=1)  # Multiclass predictions for output3\n",
    "\n",
    "    # Confusion matrices\n",
    "    print(\"Confusion Matrix for Output 1:\")\n",
    "    print(confusion_matrix(y1_test, y1_pred))\n",
    "    print(\"Confusion Matrix for Output 2:\")\n",
    "    print(confusion_matrix(y2_test, y2_pred))\n",
    "    print(\"Confusion Matrix for Output 3:\")\n",
    "    print(confusion_matrix(y3_test, y3_pred))\n",
    "\n",
    "    # Accuracy scores\n",
    "    print(\"Accuracy for Output 1:\", accuracy_score(y1_test, y1_pred))\n",
    "    print(\"Accuracy for Output 2:\", accuracy_score(y2_test, y2_pred))\n",
    "    print(\"Accuracy for Output 3:\", accuracy_score(y3_test, y3_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37ed0c6f-1d76-4f57-b601-23490d8716b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "690/690 [==============================] - 4s 3ms/step - loss: 2.1980 - output1_loss: 0.2671 - output2_loss: 1.0978 - output3_loss: 0.7856 - output1_accuracy: 0.8910 - output2_accuracy: 0.5212 - output3_accuracy: 0.7002 - val_loss: 1.0214 - val_output1_loss: 0.1281 - val_output2_loss: 0.6574 - val_output3_loss: 0.1574 - val_output1_accuracy: 0.9280 - val_output2_accuracy: 0.7046 - val_output3_accuracy: 0.9535\n",
      "Epoch 2/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.9564 - output1_loss: 0.0937 - output2_loss: 0.6153 - output3_loss: 0.1558 - output1_accuracy: 0.9703 - output2_accuracy: 0.7191 - output3_accuracy: 0.9534 - val_loss: 0.7042 - val_output1_loss: 0.0575 - val_output2_loss: 0.4959 - val_output3_loss: 0.0519 - val_output1_accuracy: 0.9949 - val_output2_accuracy: 0.7748 - val_output3_accuracy: 0.9889\n",
      "Epoch 3/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.7607 - output1_loss: 0.0545 - output2_loss: 0.5103 - output3_loss: 0.0949 - output1_accuracy: 0.9928 - output2_accuracy: 0.7601 - output3_accuracy: 0.9719 - val_loss: 0.6182 - val_output1_loss: 0.0369 - val_output2_loss: 0.4444 - val_output3_loss: 0.0355 - val_output1_accuracy: 0.9985 - val_output2_accuracy: 0.7752 - val_output3_accuracy: 0.9913\n",
      "Epoch 4/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.6916 - output1_loss: 0.0377 - output2_loss: 0.4749 - output3_loss: 0.0790 - output1_accuracy: 0.9962 - output2_accuracy: 0.7624 - output3_accuracy: 0.9761 - val_loss: 0.5790 - val_output1_loss: 0.0253 - val_output2_loss: 0.4241 - val_output3_loss: 0.0312 - val_output1_accuracy: 0.9990 - val_output2_accuracy: 0.7723 - val_output3_accuracy: 0.9920\n",
      "Epoch 5/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.6527 - output1_loss: 0.0284 - output2_loss: 0.4553 - output3_loss: 0.0720 - output1_accuracy: 0.9972 - output2_accuracy: 0.7644 - output3_accuracy: 0.9783 - val_loss: 0.5512 - val_output1_loss: 0.0186 - val_output2_loss: 0.4084 - val_output3_loss: 0.0287 - val_output1_accuracy: 0.9993 - val_output2_accuracy: 0.7827 - val_output3_accuracy: 0.9927\n",
      "Epoch 6/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.6276 - output1_loss: 0.0222 - output2_loss: 0.4429 - output3_loss: 0.0682 - output1_accuracy: 0.9977 - output2_accuracy: 0.7746 - output3_accuracy: 0.9793 - val_loss: 0.5313 - val_output1_loss: 0.0135 - val_output2_loss: 0.3974 - val_output3_loss: 0.0269 - val_output1_accuracy: 0.9993 - val_output2_accuracy: 0.7872 - val_output3_accuracy: 0.9928\n",
      "Epoch 7/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.6055 - output1_loss: 0.0175 - output2_loss: 0.4318 - output3_loss: 0.0638 - output1_accuracy: 0.9980 - output2_accuracy: 0.7810 - output3_accuracy: 0.9807 - val_loss: 0.5140 - val_output1_loss: 0.0101 - val_output2_loss: 0.3875 - val_output3_loss: 0.0248 - val_output1_accuracy: 0.9997 - val_output2_accuracy: 0.7998 - val_output3_accuracy: 0.9935\n",
      "Epoch 8/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.5896 - output1_loss: 0.0140 - output2_loss: 0.4244 - output3_loss: 0.0603 - output1_accuracy: 0.9984 - output2_accuracy: 0.7922 - output3_accuracy: 0.9819 - val_loss: 0.5021 - val_output1_loss: 0.0080 - val_output2_loss: 0.3802 - val_output3_loss: 0.0241 - val_output1_accuracy: 0.9995 - val_output2_accuracy: 0.8140 - val_output3_accuracy: 0.9934\n",
      "Epoch 9/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.5765 - output1_loss: 0.0111 - output2_loss: 0.4189 - output3_loss: 0.0576 - output1_accuracy: 0.9988 - output2_accuracy: 0.7977 - output3_accuracy: 0.9827 - val_loss: 0.4898 - val_output1_loss: 0.0061 - val_output2_loss: 0.3729 - val_output3_loss: 0.0227 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.8210 - val_output3_accuracy: 0.9939\n",
      "Epoch 10/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.5620 - output1_loss: 0.0093 - output2_loss: 0.4104 - output3_loss: 0.0550 - output1_accuracy: 0.9989 - output2_accuracy: 0.8103 - output3_accuracy: 0.9836 - val_loss: 0.4815 - val_output1_loss: 0.0048 - val_output2_loss: 0.3681 - val_output3_loss: 0.0223 - val_output1_accuracy: 0.9998 - val_output2_accuracy: 0.8331 - val_output3_accuracy: 0.9938\n",
      "Epoch 11/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.5440 - output1_loss: 0.0081 - output2_loss: 0.3961 - output3_loss: 0.0552 - output1_accuracy: 0.9990 - output2_accuracy: 0.8509 - output3_accuracy: 0.9832 - val_loss: 0.4277 - val_output1_loss: 0.0039 - val_output2_loss: 0.3192 - val_output3_loss: 0.0215 - val_output1_accuracy: 0.9998 - val_output2_accuracy: 0.9191 - val_output3_accuracy: 0.9942\n",
      "Epoch 12/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.4883 - output1_loss: 0.0072 - output2_loss: 0.3458 - output3_loss: 0.0531 - output1_accuracy: 0.9990 - output2_accuracy: 0.8813 - output3_accuracy: 0.9841 - val_loss: 0.3891 - val_output1_loss: 0.0032 - val_output2_loss: 0.2839 - val_output3_loss: 0.0205 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.8991 - val_output3_accuracy: 0.9946\n",
      "Epoch 13/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.4575 - output1_loss: 0.0063 - output2_loss: 0.3196 - output3_loss: 0.0506 - output1_accuracy: 0.9989 - output2_accuracy: 0.8799 - output3_accuracy: 0.9850 - val_loss: 0.3711 - val_output1_loss: 0.0026 - val_output2_loss: 0.2687 - val_output3_loss: 0.0194 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.8960 - val_output3_accuracy: 0.9948\n",
      "Epoch 14/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.4414 - output1_loss: 0.0055 - output2_loss: 0.3070 - output3_loss: 0.0486 - output1_accuracy: 0.9993 - output2_accuracy: 0.8821 - output3_accuracy: 0.9852 - val_loss: 0.3620 - val_output1_loss: 0.0022 - val_output2_loss: 0.2604 - val_output3_loss: 0.0195 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9031 - val_output3_accuracy: 0.9947\n",
      "Epoch 15/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.4323 - output1_loss: 0.0047 - output2_loss: 0.2997 - output3_loss: 0.0484 - output1_accuracy: 0.9994 - output2_accuracy: 0.8831 - output3_accuracy: 0.9855 - val_loss: 0.3530 - val_output1_loss: 0.0019 - val_output2_loss: 0.2538 - val_output3_loss: 0.0181 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9011 - val_output3_accuracy: 0.9949\n",
      "Epoch 16/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.3825 - output1_loss: 0.0047 - output2_loss: 0.2521 - output3_loss: 0.0470 - output1_accuracy: 0.9993 - output2_accuracy: 0.9078 - output3_accuracy: 0.9863 - val_loss: 0.2609 - val_output1_loss: 0.0018 - val_output2_loss: 0.1629 - val_output3_loss: 0.0177 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9380 - val_output3_accuracy: 0.9953\n",
      "Epoch 17/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.3033 - output1_loss: 0.0040 - output2_loss: 0.1763 - output3_loss: 0.0451 - output1_accuracy: 0.9995 - output2_accuracy: 0.9465 - output3_accuracy: 0.9862 - val_loss: 0.1722 - val_output1_loss: 0.0016 - val_output2_loss: 0.0752 - val_output3_loss: 0.0173 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9932 - val_output3_accuracy: 0.9953\n",
      "Epoch 18/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.2296 - output1_loss: 0.0037 - output2_loss: 0.1028 - output3_loss: 0.0447 - output1_accuracy: 0.9994 - output2_accuracy: 0.9814 - output3_accuracy: 0.9865 - val_loss: 0.1492 - val_output1_loss: 0.0014 - val_output2_loss: 0.0528 - val_output3_loss: 0.0168 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9934 - val_output3_accuracy: 0.9952\n",
      "Epoch 19/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.2128 - output1_loss: 0.0038 - output2_loss: 0.0882 - output3_loss: 0.0427 - output1_accuracy: 0.9992 - output2_accuracy: 0.9823 - output3_accuracy: 0.9874 - val_loss: 0.1417 - val_output1_loss: 0.0013 - val_output2_loss: 0.0458 - val_output3_loss: 0.0168 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9938 - val_output3_accuracy: 0.9953\n",
      "Epoch 20/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.2014 - output1_loss: 0.0037 - output2_loss: 0.0781 - output3_loss: 0.0422 - output1_accuracy: 0.9993 - output2_accuracy: 0.9837 - output3_accuracy: 0.9872 - val_loss: 0.1337 - val_output1_loss: 0.0013 - val_output2_loss: 0.0396 - val_output3_loss: 0.0160 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9942 - val_output3_accuracy: 0.9954\n",
      "Epoch 21/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1966 - output1_loss: 0.0034 - output2_loss: 0.0758 - output3_loss: 0.0410 - output1_accuracy: 0.9994 - output2_accuracy: 0.9839 - output3_accuracy: 0.9877 - val_loss: 0.1297 - val_output1_loss: 0.0012 - val_output2_loss: 0.0369 - val_output3_loss: 0.0156 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9942 - val_output3_accuracy: 0.9955\n",
      "Epoch 22/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1900 - output1_loss: 0.0032 - output2_loss: 0.0717 - output3_loss: 0.0397 - output1_accuracy: 0.9993 - output2_accuracy: 0.9839 - output3_accuracy: 0.9884 - val_loss: 0.1266 - val_output1_loss: 0.0011 - val_output2_loss: 0.0346 - val_output3_loss: 0.0160 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9945 - val_output3_accuracy: 0.9955\n",
      "Epoch 23/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1884 - output1_loss: 0.0032 - output2_loss: 0.0708 - output3_loss: 0.0400 - output1_accuracy: 0.9994 - output2_accuracy: 0.9846 - output3_accuracy: 0.9880 - val_loss: 0.1240 - val_output1_loss: 9.9021e-04 - val_output2_loss: 0.0332 - val_output3_loss: 0.0159 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9943 - val_output3_accuracy: 0.9953\n",
      "Epoch 24/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1835 - output1_loss: 0.0029 - output2_loss: 0.0680 - output3_loss: 0.0391 - output1_accuracy: 0.9995 - output2_accuracy: 0.9840 - output3_accuracy: 0.9884 - val_loss: 0.1207 - val_output1_loss: 9.6084e-04 - val_output2_loss: 0.0316 - val_output3_loss: 0.0152 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9947 - val_output3_accuracy: 0.9957\n",
      "Epoch 25/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1799 - output1_loss: 0.0031 - output2_loss: 0.0651 - output3_loss: 0.0392 - output1_accuracy: 0.9994 - output2_accuracy: 0.9840 - output3_accuracy: 0.9884 - val_loss: 0.1189 - val_output1_loss: 9.7990e-04 - val_output2_loss: 0.0307 - val_output3_loss: 0.0153 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9947 - val_output3_accuracy: 0.9956\n",
      "Epoch 26/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1775 - output1_loss: 0.0028 - output2_loss: 0.0640 - output3_loss: 0.0392 - output1_accuracy: 0.9994 - output2_accuracy: 0.9849 - output3_accuracy: 0.9879 - val_loss: 0.1168 - val_output1_loss: 9.3242e-04 - val_output2_loss: 0.0299 - val_output3_loss: 0.0151 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9947 - val_output3_accuracy: 0.9959\n",
      "Epoch 27/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1769 - output1_loss: 0.0028 - output2_loss: 0.0640 - output3_loss: 0.0397 - output1_accuracy: 0.9995 - output2_accuracy: 0.9847 - output3_accuracy: 0.9881 - val_loss: 0.1148 - val_output1_loss: 8.7188e-04 - val_output2_loss: 0.0294 - val_output3_loss: 0.0148 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9947 - val_output3_accuracy: 0.9958\n",
      "Epoch 28/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1704 - output1_loss: 0.0025 - output2_loss: 0.0605 - output3_loss: 0.0379 - output1_accuracy: 0.9996 - output2_accuracy: 0.9861 - output3_accuracy: 0.9888 - val_loss: 0.1133 - val_output1_loss: 8.7107e-04 - val_output2_loss: 0.0285 - val_output3_loss: 0.0150 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9947 - val_output3_accuracy: 0.9955\n",
      "Epoch 29/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1692 - output1_loss: 0.0024 - output2_loss: 0.0597 - output3_loss: 0.0385 - output1_accuracy: 0.9995 - output2_accuracy: 0.9858 - output3_accuracy: 0.9882 - val_loss: 0.1108 - val_output1_loss: 8.4364e-04 - val_output2_loss: 0.0268 - val_output3_loss: 0.0148 - val_output1_accuracy: 0.9998 - val_output2_accuracy: 0.9952 - val_output3_accuracy: 0.9958\n",
      "Epoch 30/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1649 - output1_loss: 0.0027 - output2_loss: 0.0567 - output3_loss: 0.0375 - output1_accuracy: 0.9994 - output2_accuracy: 0.9861 - output3_accuracy: 0.9885 - val_loss: 0.1091 - val_output1_loss: 7.7254e-04 - val_output2_loss: 0.0260 - val_output3_loss: 0.0146 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9953 - val_output3_accuracy: 0.9956\n",
      "Epoch 31/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1656 - output1_loss: 0.0025 - output2_loss: 0.0571 - output3_loss: 0.0386 - output1_accuracy: 0.9994 - output2_accuracy: 0.9864 - output3_accuracy: 0.9884 - val_loss: 0.1076 - val_output1_loss: 7.9275e-04 - val_output2_loss: 0.0254 - val_output3_loss: 0.0144 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9956 - val_output3_accuracy: 0.9959\n",
      "Epoch 32/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1609 - output1_loss: 0.0024 - output2_loss: 0.0546 - output3_loss: 0.0374 - output1_accuracy: 0.9995 - output2_accuracy: 0.9873 - output3_accuracy: 0.9887 - val_loss: 0.1066 - val_output1_loss: 7.7200e-04 - val_output2_loss: 0.0249 - val_output3_loss: 0.0150 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9954 - val_output3_accuracy: 0.9958\n",
      "Epoch 33/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1590 - output1_loss: 0.0026 - output2_loss: 0.0543 - output3_loss: 0.0365 - output1_accuracy: 0.9995 - output2_accuracy: 0.9871 - output3_accuracy: 0.9890 - val_loss: 0.1048 - val_output1_loss: 7.9924e-04 - val_output2_loss: 0.0247 - val_output3_loss: 0.0139 - val_output1_accuracy: 0.9998 - val_output2_accuracy: 0.9953 - val_output3_accuracy: 0.9959\n",
      "Epoch 34/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1585 - output1_loss: 0.0025 - output2_loss: 0.0539 - output3_loss: 0.0372 - output1_accuracy: 0.9995 - output2_accuracy: 0.9867 - output3_accuracy: 0.9885 - val_loss: 0.1042 - val_output1_loss: 7.4662e-04 - val_output2_loss: 0.0245 - val_output3_loss: 0.0141 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9952 - val_output3_accuracy: 0.9958\n",
      "Epoch 35/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1587 - output1_loss: 0.0027 - output2_loss: 0.0531 - output3_loss: 0.0385 - output1_accuracy: 0.9994 - output2_accuracy: 0.9866 - output3_accuracy: 0.9880 - val_loss: 0.1019 - val_output1_loss: 6.9084e-04 - val_output2_loss: 0.0232 - val_output3_loss: 0.0141 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.9953 - val_output3_accuracy: 0.9960\n",
      "Epoch 36/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1566 - output1_loss: 0.0024 - output2_loss: 0.0535 - output3_loss: 0.0373 - output1_accuracy: 0.9995 - output2_accuracy: 0.9869 - output3_accuracy: 0.9891 - val_loss: 0.1007 - val_output1_loss: 6.6120e-04 - val_output2_loss: 0.0231 - val_output3_loss: 0.0138 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9956 - val_output3_accuracy: 0.9958\n",
      "Epoch 37/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1540 - output1_loss: 0.0023 - output2_loss: 0.0514 - output3_loss: 0.0372 - output1_accuracy: 0.9995 - output2_accuracy: 0.9874 - output3_accuracy: 0.9888 - val_loss: 0.1003 - val_output1_loss: 6.8896e-04 - val_output2_loss: 0.0228 - val_output3_loss: 0.0142 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9954 - val_output3_accuracy: 0.9957\n",
      "Epoch 38/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1522 - output1_loss: 0.0024 - output2_loss: 0.0503 - output3_loss: 0.0372 - output1_accuracy: 0.9995 - output2_accuracy: 0.9874 - output3_accuracy: 0.9881 - val_loss: 0.0986 - val_output1_loss: 6.7014e-04 - val_output2_loss: 0.0219 - val_output3_loss: 0.0140 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9957 - val_output3_accuracy: 0.9956\n",
      "Epoch 39/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.1490 - output1_loss: 0.0022 - output2_loss: 0.0491 - output3_loss: 0.0360 - output1_accuracy: 0.9995 - output2_accuracy: 0.9876 - output3_accuracy: 0.9889 - val_loss: 0.0975 - val_output1_loss: 6.5267e-04 - val_output2_loss: 0.0219 - val_output3_loss: 0.0137 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9955 - val_output3_accuracy: 0.9959\n",
      "Epoch 40/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1507 - output1_loss: 0.0023 - output2_loss: 0.0501 - output3_loss: 0.0372 - output1_accuracy: 0.9996 - output2_accuracy: 0.9872 - output3_accuracy: 0.9886 - val_loss: 0.0968 - val_output1_loss: 7.7197e-04 - val_output2_loss: 0.0213 - val_output3_loss: 0.0140 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9956 - val_output3_accuracy: 0.9958\n",
      "Epoch 41/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1483 - output1_loss: 0.0026 - output2_loss: 0.0494 - output3_loss: 0.0356 - output1_accuracy: 0.9994 - output2_accuracy: 0.9874 - output3_accuracy: 0.9891 - val_loss: 0.0961 - val_output1_loss: 7.0549e-04 - val_output2_loss: 0.0214 - val_output3_loss: 0.0136 - val_output1_accuracy: 0.9998 - val_output2_accuracy: 0.9955 - val_output3_accuracy: 0.9957\n",
      "Epoch 42/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1468 - output1_loss: 0.0024 - output2_loss: 0.0486 - output3_loss: 0.0358 - output1_accuracy: 0.9994 - output2_accuracy: 0.9880 - output3_accuracy: 0.9887 - val_loss: 0.0955 - val_output1_loss: 6.8467e-04 - val_output2_loss: 0.0215 - val_output3_loss: 0.0136 - val_output1_accuracy: 0.9998 - val_output2_accuracy: 0.9954 - val_output3_accuracy: 0.9960\n",
      "Epoch 43/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1439 - output1_loss: 0.0021 - output2_loss: 0.0473 - output3_loss: 0.0349 - output1_accuracy: 0.9996 - output2_accuracy: 0.9881 - output3_accuracy: 0.9897 - val_loss: 0.0948 - val_output1_loss: 6.2233e-04 - val_output2_loss: 0.0208 - val_output3_loss: 0.0141 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9954 - val_output3_accuracy: 0.9958\n",
      "Epoch 44/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1453 - output1_loss: 0.0022 - output2_loss: 0.0487 - output3_loss: 0.0353 - output1_accuracy: 0.9995 - output2_accuracy: 0.9875 - output3_accuracy: 0.9894 - val_loss: 0.0937 - val_output1_loss: 6.4786e-04 - val_output2_loss: 0.0205 - val_output3_loss: 0.0139 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9956 - val_output3_accuracy: 0.9961\n",
      "Epoch 45/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1451 - output1_loss: 0.0023 - output2_loss: 0.0483 - output3_loss: 0.0359 - output1_accuracy: 0.9995 - output2_accuracy: 0.9876 - output3_accuracy: 0.9889 - val_loss: 0.0924 - val_output1_loss: 5.6600e-04 - val_output2_loss: 0.0201 - val_output3_loss: 0.0132 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9957 - val_output3_accuracy: 0.9960\n",
      "Epoch 46/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1433 - output1_loss: 0.0021 - output2_loss: 0.0480 - output3_loss: 0.0349 - output1_accuracy: 0.9995 - output2_accuracy: 0.9880 - output3_accuracy: 0.9892 - val_loss: 0.0929 - val_output1_loss: 6.4018e-04 - val_output2_loss: 0.0205 - val_output3_loss: 0.0135 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9955 - val_output3_accuracy: 0.9959\n",
      "Epoch 47/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1436 - output1_loss: 0.0023 - output2_loss: 0.0477 - output3_loss: 0.0358 - output1_accuracy: 0.9995 - output2_accuracy: 0.9878 - output3_accuracy: 0.9888 - val_loss: 0.0911 - val_output1_loss: 6.0659e-04 - val_output2_loss: 0.0200 - val_output3_loss: 0.0130 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9955 - val_output3_accuracy: 0.9960\n",
      "Epoch 48/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1415 - output1_loss: 0.0021 - output2_loss: 0.0473 - output3_loss: 0.0349 - output1_accuracy: 0.9995 - output2_accuracy: 0.9880 - output3_accuracy: 0.9891 - val_loss: 0.0903 - val_output1_loss: 6.4726e-04 - val_output2_loss: 0.0197 - val_output3_loss: 0.0129 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9957 - val_output3_accuracy: 0.9960\n",
      "Epoch 49/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1423 - output1_loss: 0.0021 - output2_loss: 0.0479 - output3_loss: 0.0355 - output1_accuracy: 0.9995 - output2_accuracy: 0.9873 - output3_accuracy: 0.9893 - val_loss: 0.0906 - val_output1_loss: 6.1784e-04 - val_output2_loss: 0.0197 - val_output3_loss: 0.0134 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9956 - val_output3_accuracy: 0.9958\n",
      "Epoch 50/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1411 - output1_loss: 0.0022 - output2_loss: 0.0467 - output3_loss: 0.0355 - output1_accuracy: 0.9995 - output2_accuracy: 0.9879 - output3_accuracy: 0.9888 - val_loss: 0.0904 - val_output1_loss: 6.1782e-04 - val_output2_loss: 0.0200 - val_output3_loss: 0.0134 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9955 - val_output3_accuracy: 0.9961\n",
      "Model saved as ed_9x9.keras\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0875 - output1_loss: 5.1919e-04 - output2_loss: 0.0178 - output3_loss: 0.0128 - output1_accuracy: 0.9999 - output2_accuracy: 0.9963 - output3_accuracy: 0.9962\n",
      "Test Results: [0.08747925609350204, 0.0005191855598241091, 0.017785649746656418, 0.012795639224350452, 0.9999259114265442, 0.9963333606719971, 0.996222198009491]\n",
      "1688/1688 [==============================] - 3s 1ms/step\n",
      "Confusion Matrix for Output 1:\n",
      "[[ 5872     3]\n",
      " [    1 48124]]\n",
      "Confusion Matrix for Output 2:\n",
      "[[ 5868     1     3     3     0]\n",
      " [    1 11974    22     1     6]\n",
      " [    6    13 11964    10     0]\n",
      " [   12     0    17 11959    19]\n",
      " [    0    38     0    46 12037]]\n",
      "Confusion Matrix for Output 3:\n",
      "[[ 2933     1     4     2     0]\n",
      " [    2 14838     4     2    66]\n",
      " [    4     9 12071    23     3]\n",
      " [    0     9    10 12087     6]\n",
      " [    0    55     1     3 11867]]\n",
      "Accuracy for Output 1: 0.9999259259259259\n",
      "Accuracy for Output 2: 0.9963333333333333\n",
      "Accuracy for Output 3: 0.9962222222222222\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data('C:\\Ankit\\Programs\\RP\\data\\\\train\\mat_3x3.csv')\n",
    "train_and_evaluate_multi_output_model(X_train, X_test, y_train, y_test, input_size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a9063d3-b7fa-40ce-add5-cafebb48ed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "690/690 [==============================] - 5s 5ms/step - loss: 1.4816 - output1_loss: 0.1679 - output2_loss: 0.6305 - output3_loss: 0.6158 - output1_accuracy: 0.9369 - output2_accuracy: 0.7750 - output3_accuracy: 0.7715 - val_loss: 0.3359 - val_output1_loss: 0.0644 - val_output2_loss: 0.0543 - val_output3_loss: 0.1103 - val_output1_accuracy: 0.9990 - val_output2_accuracy: 0.9996 - val_output3_accuracy: 0.9911\n",
      "Epoch 2/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.2431 - output1_loss: 0.0515 - output2_loss: 0.0386 - output3_loss: 0.0466 - output1_accuracy: 0.9983 - output2_accuracy: 0.9974 - output3_accuracy: 0.9929 - val_loss: 0.1594 - val_output1_loss: 0.0398 - val_output2_loss: 0.0113 - val_output3_loss: 0.0095 - val_output1_accuracy: 0.9999 - val_output2_accuracy: 0.9998 - val_output3_accuracy: 0.9994\n",
      "Epoch 3/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1595 - output1_loss: 0.0331 - output2_loss: 0.0177 - output3_loss: 0.0200 - output1_accuracy: 0.9996 - output2_accuracy: 0.9986 - output3_accuracy: 0.9971 - val_loss: 0.1184 - val_output1_loss: 0.0264 - val_output2_loss: 0.0066 - val_output3_loss: 0.0058 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.9999 - val_output3_accuracy: 0.9998\n",
      "Epoch 4/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1222 - output1_loss: 0.0224 - output2_loss: 0.0128 - output3_loss: 0.0148 - output1_accuracy: 0.9998 - output2_accuracy: 0.9991 - output3_accuracy: 0.9977 - val_loss: 0.0937 - val_output1_loss: 0.0181 - val_output2_loss: 0.0051 - val_output3_loss: 0.0045 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.9999 - val_output3_accuracy: 0.9999\n",
      "Epoch 5/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0995 - output1_loss: 0.0158 - output2_loss: 0.0105 - output3_loss: 0.0117 - output1_accuracy: 0.9999 - output2_accuracy: 0.9993 - output3_accuracy: 0.9984 - val_loss: 0.0784 - val_output1_loss: 0.0129 - val_output2_loss: 0.0043 - val_output3_loss: 0.0035 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.9999 - val_output3_accuracy: 0.9999\n",
      "Epoch 6/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0851 - output1_loss: 0.0113 - output2_loss: 0.0089 - output3_loss: 0.0100 - output1_accuracy: 1.0000 - output2_accuracy: 0.9991 - output3_accuracy: 0.9986 - val_loss: 0.0680 - val_output1_loss: 0.0091 - val_output2_loss: 0.0032 - val_output3_loss: 0.0031 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 7/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0747 - output1_loss: 0.0083 - output2_loss: 0.0073 - output3_loss: 0.0086 - output1_accuracy: 1.0000 - output2_accuracy: 0.9995 - output3_accuracy: 0.9989 - val_loss: 0.0609 - val_output1_loss: 0.0067 - val_output2_loss: 0.0030 - val_output3_loss: 0.0028 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.9999 - val_output3_accuracy: 0.9999\n",
      "Epoch 8/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0672 - output1_loss: 0.0062 - output2_loss: 0.0065 - output3_loss: 0.0076 - output1_accuracy: 1.0000 - output2_accuracy: 0.9995 - output3_accuracy: 0.9990 - val_loss: 0.0553 - val_output1_loss: 0.0050 - val_output2_loss: 0.0028 - val_output3_loss: 0.0025 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.9999 - val_output3_accuracy: 0.9999\n",
      "Epoch 9/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0613 - output1_loss: 0.0047 - output2_loss: 0.0056 - output3_loss: 0.0072 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9991 - val_loss: 0.0508 - val_output1_loss: 0.0038 - val_output2_loss: 0.0022 - val_output3_loss: 0.0023 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0568 - output1_loss: 0.0036 - output2_loss: 0.0052 - output3_loss: 0.0067 - output1_accuracy: 1.0000 - output2_accuracy: 0.9996 - output3_accuracy: 0.9991 - val_loss: 0.0475 - val_output1_loss: 0.0028 - val_output2_loss: 0.0023 - val_output3_loss: 0.0022 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.9999 - val_output3_accuracy: 0.9999\n",
      "Epoch 11/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0527 - output1_loss: 0.0028 - output2_loss: 0.0047 - output3_loss: 0.0063 - output1_accuracy: 1.0000 - output2_accuracy: 0.9996 - output3_accuracy: 0.9991 - val_loss: 0.0435 - val_output1_loss: 0.0022 - val_output2_loss: 0.0017 - val_output3_loss: 0.0018 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 12/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0485 - output1_loss: 0.0022 - output2_loss: 0.0042 - output3_loss: 0.0055 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9994 - val_loss: 0.0405 - val_output1_loss: 0.0016 - val_output2_loss: 0.0016 - val_output3_loss: 0.0018 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 13/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0457 - output1_loss: 0.0017 - output2_loss: 0.0038 - output3_loss: 0.0056 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9992 - val_loss: 0.0379 - val_output1_loss: 0.0012 - val_output2_loss: 0.0014 - val_output3_loss: 0.0018 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 14/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0431 - output1_loss: 0.0014 - output2_loss: 0.0035 - output3_loss: 0.0055 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9991 - val_loss: 0.0359 - val_output1_loss: 9.5119e-04 - val_output2_loss: 0.0014 - val_output3_loss: 0.0018 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 15/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0406 - output1_loss: 0.0011 - output2_loss: 0.0033 - output3_loss: 0.0051 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9994 - val_loss: 0.0338 - val_output1_loss: 7.5145e-04 - val_output2_loss: 0.0012 - val_output3_loss: 0.0016 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 16/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0388 - output1_loss: 9.2716e-04 - output2_loss: 0.0031 - output3_loss: 0.0051 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9992 - val_loss: 0.0323 - val_output1_loss: 5.7894e-04 - val_output2_loss: 0.0010 - val_output3_loss: 0.0014 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0368 - output1_loss: 7.5771e-04 - output2_loss: 0.0029 - output3_loss: 0.0048 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9994 - val_loss: 0.0305 - val_output1_loss: 4.6364e-04 - val_output2_loss: 0.0010 - val_output3_loss: 0.0014 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 18/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0353 - output1_loss: 6.4890e-04 - output2_loss: 0.0027 - output3_loss: 0.0046 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9993 - val_loss: 0.0296 - val_output1_loss: 3.8104e-04 - val_output2_loss: 9.1259e-04 - val_output3_loss: 0.0016 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0342 - output1_loss: 5.6554e-04 - output2_loss: 0.0028 - output3_loss: 0.0046 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9993 - val_loss: 0.0281 - val_output1_loss: 3.1173e-04 - val_output2_loss: 8.9068e-04 - val_output3_loss: 0.0013 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0326 - output1_loss: 4.7708e-04 - output2_loss: 0.0024 - output3_loss: 0.0046 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0273 - val_output1_loss: 2.9145e-04 - val_output2_loss: 0.0010 - val_output3_loss: 0.0014 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0314 - output1_loss: 4.4012e-04 - output2_loss: 0.0024 - output3_loss: 0.0043 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0263 - val_output1_loss: 2.0757e-04 - val_output2_loss: 8.5275e-04 - val_output3_loss: 0.0013 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 22/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0304 - output1_loss: 3.8091e-04 - output2_loss: 0.0023 - output3_loss: 0.0042 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9994 - val_loss: 0.0252 - val_output1_loss: 1.8894e-04 - val_output2_loss: 7.6037e-04 - val_output3_loss: 0.0013 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 23/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0296 - output1_loss: 3.6698e-04 - output2_loss: 0.0021 - output3_loss: 0.0043 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9994 - val_loss: 0.0245 - val_output1_loss: 1.6123e-04 - val_output2_loss: 6.9159e-04 - val_output3_loss: 0.0012 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 24/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0287 - output1_loss: 3.4190e-04 - output2_loss: 0.0022 - output3_loss: 0.0041 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9994 - val_loss: 0.0241 - val_output1_loss: 1.2475e-04 - val_output2_loss: 7.1100e-04 - val_output3_loss: 0.0014 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 25/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0279 - output1_loss: 2.9984e-04 - output2_loss: 0.0021 - output3_loss: 0.0041 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9994 - val_loss: 0.0234 - val_output1_loss: 1.2536e-04 - val_output2_loss: 6.5613e-04 - val_output3_loss: 0.0012 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 26/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0271 - output1_loss: 2.9636e-04 - output2_loss: 0.0021 - output3_loss: 0.0037 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0226 - val_output1_loss: 1.1394e-04 - val_output2_loss: 5.7669e-04 - val_output3_loss: 0.0011 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 27/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0262 - output1_loss: 2.7794e-04 - output2_loss: 0.0019 - output3_loss: 0.0037 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9996 - val_loss: 0.0218 - val_output1_loss: 1.3275e-04 - val_output2_loss: 5.8024e-04 - val_output3_loss: 9.7988e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0261 - output1_loss: 2.6323e-04 - output2_loss: 0.0020 - output3_loss: 0.0040 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9994 - val_loss: 0.0213 - val_output1_loss: 1.2131e-04 - val_output2_loss: 5.9119e-04 - val_output3_loss: 9.1835e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0250 - output1_loss: 2.4749e-04 - output2_loss: 0.0018 - output3_loss: 0.0036 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0205 - val_output1_loss: 1.1299e-04 - val_output2_loss: 5.8314e-04 - val_output3_loss: 9.2275e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0246 - output1_loss: 2.4359e-04 - output2_loss: 0.0018 - output3_loss: 0.0037 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0204 - val_output1_loss: 9.3232e-05 - val_output2_loss: 5.5516e-04 - val_output3_loss: 8.8517e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0243 - output1_loss: 2.5307e-04 - output2_loss: 0.0018 - output3_loss: 0.0038 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9993 - val_loss: 0.0201 - val_output1_loss: 8.0563e-05 - val_output2_loss: 5.7123e-04 - val_output3_loss: 0.0011 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 32/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0239 - output1_loss: 2.4299e-04 - output2_loss: 0.0017 - output3_loss: 0.0037 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9994 - val_loss: 0.0195 - val_output1_loss: 8.6887e-05 - val_output2_loss: 4.9842e-04 - val_output3_loss: 0.0010 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 33/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0234 - output1_loss: 2.0631e-04 - output2_loss: 0.0018 - output3_loss: 0.0036 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9994 - val_loss: 0.0190 - val_output1_loss: 8.7435e-05 - val_output2_loss: 5.0291e-04 - val_output3_loss: 8.6857e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0227 - output1_loss: 2.0587e-04 - output2_loss: 0.0016 - output3_loss: 0.0034 - output1_accuracy: 1.0000 - output2_accuracy: 1.0000 - output3_accuracy: 0.9995 - val_loss: 0.0186 - val_output1_loss: 8.2398e-05 - val_output2_loss: 4.5631e-04 - val_output3_loss: 8.0088e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0227 - output1_loss: 2.1432e-04 - output2_loss: 0.0016 - output3_loss: 0.0036 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0185 - val_output1_loss: 7.4994e-05 - val_output2_loss: 5.0961e-04 - val_output3_loss: 8.1062e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 36/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0221 - output1_loss: 1.9467e-04 - output2_loss: 0.0017 - output3_loss: 0.0034 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9994 - val_loss: 0.0181 - val_output1_loss: 9.5130e-05 - val_output2_loss: 4.7903e-04 - val_output3_loss: 8.6132e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0217 - output1_loss: 2.1592e-04 - output2_loss: 0.0015 - output3_loss: 0.0033 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0177 - val_output1_loss: 6.9856e-05 - val_output2_loss: 4.4599e-04 - val_output3_loss: 8.4892e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 38/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0214 - output1_loss: 1.9382e-04 - output2_loss: 0.0016 - output3_loss: 0.0033 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0176 - val_output1_loss: 7.3154e-05 - val_output2_loss: 4.2545e-04 - val_output3_loss: 8.0595e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0209 - output1_loss: 1.8195e-04 - output2_loss: 0.0015 - output3_loss: 0.0032 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0172 - val_output1_loss: 6.3100e-05 - val_output2_loss: 4.2287e-04 - val_output3_loss: 8.0116e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0205 - output1_loss: 1.8401e-04 - output2_loss: 0.0016 - output3_loss: 0.0030 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9996 - val_loss: 0.0175 - val_output1_loss: 8.8176e-05 - val_output2_loss: 5.5415e-04 - val_output3_loss: 8.1007e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0203 - output1_loss: 1.6152e-04 - output2_loss: 0.0014 - output3_loss: 0.0032 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0166 - val_output1_loss: 6.6626e-05 - val_output2_loss: 4.2630e-04 - val_output3_loss: 7.3356e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0201 - output1_loss: 2.1096e-04 - output2_loss: 0.0014 - output3_loss: 0.0032 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9994 - val_loss: 0.0171 - val_output1_loss: 1.2392e-04 - val_output2_loss: 6.5231e-04 - val_output3_loss: 9.7593e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 43/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0202 - output1_loss: 2.0598e-04 - output2_loss: 0.0015 - output3_loss: 0.0032 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0165 - val_output1_loss: 4.1383e-05 - val_output2_loss: 5.3856e-04 - val_output3_loss: 6.8591e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0197 - output1_loss: 1.5044e-04 - output2_loss: 0.0013 - output3_loss: 0.0032 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9994 - val_loss: 0.0160 - val_output1_loss: 6.2732e-05 - val_output2_loss: 3.8829e-04 - val_output3_loss: 7.3645e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0197 - output1_loss: 1.7956e-04 - output2_loss: 0.0013 - output3_loss: 0.0033 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9994 - val_loss: 0.0158 - val_output1_loss: 3.7640e-05 - val_output2_loss: 3.8557e-04 - val_output3_loss: 6.7203e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0194 - output1_loss: 1.7689e-04 - output2_loss: 0.0015 - output3_loss: 0.0031 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0160 - val_output1_loss: 4.3470e-05 - val_output2_loss: 4.6362e-04 - val_output3_loss: 7.4241e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0190 - output1_loss: 1.4820e-04 - output2_loss: 0.0014 - output3_loss: 0.0030 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9996 - val_loss: 0.0158 - val_output1_loss: 5.0939e-05 - val_output2_loss: 5.7658e-04 - val_output3_loss: 8.6467e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 48/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0188 - output1_loss: 1.5334e-04 - output2_loss: 0.0014 - output3_loss: 0.0031 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9994 - val_loss: 0.0156 - val_output1_loss: 2.7252e-05 - val_output2_loss: 3.9514e-04 - val_output3_loss: 7.4103e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0183 - output1_loss: 1.4107e-04 - output2_loss: 0.0012 - output3_loss: 0.0029 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0150 - val_output1_loss: 4.5521e-05 - val_output2_loss: 3.3357e-04 - val_output3_loss: 6.7102e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0184 - output1_loss: 1.9371e-04 - output2_loss: 0.0013 - output3_loss: 0.0029 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0153 - val_output1_loss: 4.9466e-05 - val_output2_loss: 3.2475e-04 - val_output3_loss: 7.0498e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Model saved as ed_25x25.keras\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0155 - output1_loss: 5.0377e-05 - output2_loss: 3.3286e-04 - output3_loss: 8.1409e-04 - output1_accuracy: 1.0000 - output2_accuracy: 1.0000 - output3_accuracy: 0.9999\n",
      "Test Results: [0.015462133102118969, 5.037742084823549e-05, 0.00033286013058386743, 0.0008140943828038871, 1.0, 1.0, 0.9999259114265442]\n",
      "1688/1688 [==============================] - 2s 1ms/step\n",
      "Confusion Matrix for Output 1:\n",
      "[[ 5875     0]\n",
      " [    0 48125]]\n",
      "Confusion Matrix for Output 2:\n",
      "[[ 5875     0     0     0     0]\n",
      " [    0 12004     0     0     0]\n",
      " [    0     0 11993     0     0]\n",
      " [    0     0     0 12007     0]\n",
      " [    0     0     0     0 12121]]\n",
      "Confusion Matrix for Output 3:\n",
      "[[ 2940     0     0     0     0]\n",
      " [    0 14911     0     1     0]\n",
      " [    0     0 12110     0     0]\n",
      " [    0     2     0 12110     0]\n",
      " [    0     0     1     0 11925]]\n",
      "Accuracy for Output 1: 1.0\n",
      "Accuracy for Output 2: 1.0\n",
      "Accuracy for Output 3: 0.9999259259259259\n"
     ]
    }
   ],
   "source": [
    "#5x5\n",
    "X_train, X_test, y_train, y_test = load_data('C:\\Ankit\\Programs\\RP\\data\\\\train\\mat_5x5.csv')\n",
    "train_and_evaluate_multi_output_model(X_train, X_test, y_train, y_test, input_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2191f939-4f56-4024-9d94-1768e0375173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "690/690 [==============================] - 5s 4ms/step - loss: 1.3376 - output1_loss: 0.1322 - output2_loss: 0.7417 - output3_loss: 0.3996 - output1_accuracy: 0.9520 - output2_accuracy: 0.6995 - output3_accuracy: 0.8623 - val_loss: 0.5458 - val_output1_loss: 0.0086 - val_output2_loss: 0.3885 - val_output3_loss: 0.0636 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.8325 - val_output3_accuracy: 0.9952\n",
      "Epoch 2/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.4468 - output1_loss: 0.0039 - output2_loss: 0.3357 - output3_loss: 0.0298 - output1_accuracy: 1.0000 - output2_accuracy: 0.8425 - output3_accuracy: 0.9976 - val_loss: 0.3142 - val_output1_loss: 0.0019 - val_output2_loss: 0.2352 - val_output3_loss: 0.0048 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.8894 - val_output3_accuracy: 0.9999\n",
      "Epoch 3/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.2891 - output1_loss: 0.0019 - output2_loss: 0.2115 - output3_loss: 0.0119 - output1_accuracy: 1.0000 - output2_accuracy: 0.9044 - output3_accuracy: 0.9985 - val_loss: 0.2112 - val_output1_loss: 0.0012 - val_output2_loss: 0.1514 - val_output3_loss: 0.0035 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.9983 - val_output3_accuracy: 0.9999\n",
      "Epoch 4/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.1670 - output1_loss: 0.0012 - output2_loss: 0.1017 - output3_loss: 0.0101 - output1_accuracy: 1.0000 - output2_accuracy: 0.9957 - output3_accuracy: 0.9985 - val_loss: 0.1031 - val_output1_loss: 7.4190e-04 - val_output2_loss: 0.0458 - val_output3_loss: 0.0025 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.9998 - val_output3_accuracy: 0.9999\n",
      "Epoch 5/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0994 - output1_loss: 8.0202e-04 - output2_loss: 0.0390 - output3_loss: 0.0083 - output1_accuracy: 1.0000 - output2_accuracy: 0.9988 - output3_accuracy: 0.9987 - val_loss: 0.0759 - val_output1_loss: 5.2868e-04 - val_output2_loss: 0.0245 - val_output3_loss: 0.0024 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 6/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0783 - output1_loss: 5.9434e-04 - output2_loss: 0.0239 - output3_loss: 0.0074 - output1_accuracy: 1.0000 - output2_accuracy: 0.9992 - output3_accuracy: 0.9989 - val_loss: 0.0621 - val_output1_loss: 3.8784e-04 - val_output2_loss: 0.0156 - val_output3_loss: 0.0018 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0678 - output1_loss: 4.6369e-04 - output2_loss: 0.0175 - output3_loss: 0.0070 - output1_accuracy: 1.0000 - output2_accuracy: 0.9992 - output3_accuracy: 0.9988 - val_loss: 0.0545 - val_output1_loss: 2.9352e-04 - val_output2_loss: 0.0111 - val_output3_loss: 0.0015 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.9999 - val_output3_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0604 - output1_loss: 3.7353e-04 - output2_loss: 0.0132 - output3_loss: 0.0065 - output1_accuracy: 1.0000 - output2_accuracy: 0.9994 - output3_accuracy: 0.9989 - val_loss: 0.0495 - val_output1_loss: 2.8760e-04 - val_output2_loss: 0.0082 - val_output3_loss: 0.0016 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0547 - output1_loss: 3.0905e-04 - output2_loss: 0.0106 - output3_loss: 0.0056 - output1_accuracy: 1.0000 - output2_accuracy: 0.9996 - output3_accuracy: 0.9991 - val_loss: 0.0452 - val_output1_loss: 2.0918e-04 - val_output2_loss: 0.0063 - val_output3_loss: 0.0016 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 10/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0513 - output1_loss: 2.6044e-04 - output2_loss: 0.0088 - output3_loss: 0.0059 - output1_accuracy: 1.0000 - output2_accuracy: 0.9996 - output3_accuracy: 0.9989 - val_loss: 0.0425 - val_output1_loss: 2.0273e-04 - val_output2_loss: 0.0054 - val_output3_loss: 0.0013 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0478 - output1_loss: 2.2306e-04 - output2_loss: 0.0074 - output3_loss: 0.0054 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9990 - val_loss: 0.0401 - val_output1_loss: 1.5071e-04 - val_output2_loss: 0.0048 - val_output3_loss: 0.0011 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0448 - output1_loss: 1.9120e-04 - output2_loss: 0.0065 - output3_loss: 0.0049 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9992 - val_loss: 0.0376 - val_output1_loss: 1.4568e-04 - val_output2_loss: 0.0040 - val_output3_loss: 9.3497e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0427 - output1_loss: 1.6744e-04 - output2_loss: 0.0059 - output3_loss: 0.0047 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9993 - val_loss: 0.0361 - val_output1_loss: 1.2824e-04 - val_output2_loss: 0.0036 - val_output3_loss: 0.0012 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 0.9999 - val_output3_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0402 - output1_loss: 1.4524e-04 - output2_loss: 0.0054 - output3_loss: 0.0042 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9994 - val_loss: 0.0341 - val_output1_loss: 1.3784e-04 - val_output2_loss: 0.0030 - val_output3_loss: 0.0010 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0386 - output1_loss: 1.2758e-04 - output2_loss: 0.0050 - output3_loss: 0.0042 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9993 - val_loss: 0.0323 - val_output1_loss: 1.1245e-04 - val_output2_loss: 0.0028 - val_output3_loss: 7.6960e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0368 - output1_loss: 1.1202e-04 - output2_loss: 0.0050 - output3_loss: 0.0037 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9995 - val_loss: 0.0311 - val_output1_loss: 6.6936e-05 - val_output2_loss: 0.0028 - val_output3_loss: 8.1953e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0353 - output1_loss: 9.7622e-05 - output2_loss: 0.0045 - output3_loss: 0.0037 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9995 - val_loss: 0.0295 - val_output1_loss: 7.1407e-05 - val_output2_loss: 0.0021 - val_output3_loss: 6.8509e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0341 - output1_loss: 8.7088e-05 - output2_loss: 0.0042 - output3_loss: 0.0036 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9995 - val_loss: 0.0287 - val_output1_loss: 6.3012e-05 - val_output2_loss: 0.0022 - val_output3_loss: 6.9251e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0333 - output1_loss: 7.7722e-05 - output2_loss: 0.0041 - output3_loss: 0.0037 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9994 - val_loss: 0.0281 - val_output1_loss: 5.6190e-05 - val_output2_loss: 0.0023 - val_output3_loss: 6.0672e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0323 - output1_loss: 7.0316e-05 - output2_loss: 0.0039 - output3_loss: 0.0037 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9993 - val_loss: 0.0275 - val_output1_loss: 4.3637e-05 - val_output2_loss: 0.0026 - val_output3_loss: 6.2893e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0311 - output1_loss: 6.2735e-05 - output2_loss: 0.0038 - output3_loss: 0.0033 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9996 - val_loss: 0.0270 - val_output1_loss: 4.4222e-05 - val_output2_loss: 0.0018 - val_output3_loss: 0.0014 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 22/50\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0303 - output1_loss: 5.7447e-05 - output2_loss: 0.0035 - output3_loss: 0.0035 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9993 - val_loss: 0.0255 - val_output1_loss: 3.4931e-05 - val_output2_loss: 0.0017 - val_output3_loss: 6.4415e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0294 - output1_loss: 5.2763e-05 - output2_loss: 0.0035 - output3_loss: 0.0032 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9995 - val_loss: 0.0249 - val_output1_loss: 3.3439e-05 - val_output2_loss: 0.0017 - val_output3_loss: 5.6541e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "690/690 [==============================] - 2s 4ms/step - loss: 0.0281 - output1_loss: 4.7987e-05 - output2_loss: 0.0031 - output3_loss: 0.0030 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9996 - val_loss: 0.0240 - val_output1_loss: 4.3691e-05 - val_output2_loss: 0.0018 - val_output3_loss: 5.0427e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0277 - output1_loss: 4.4452e-05 - output2_loss: 0.0032 - output3_loss: 0.0032 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9995 - val_loss: 0.0235 - val_output1_loss: 4.5636e-05 - val_output2_loss: 0.0016 - val_output3_loss: 7.5945e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0275 - output1_loss: 4.1025e-05 - output2_loss: 0.0032 - output3_loss: 0.0031 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9996 - val_loss: 0.0231 - val_output1_loss: 2.8360e-05 - val_output2_loss: 0.0015 - val_output3_loss: 6.6921e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0266 - output1_loss: 3.8984e-05 - output2_loss: 0.0032 - output3_loss: 0.0027 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9996 - val_loss: 0.0223 - val_output1_loss: 1.5442e-05 - val_output2_loss: 0.0013 - val_output3_loss: 7.7590e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0262 - output1_loss: 3.5865e-05 - output2_loss: 0.0031 - output3_loss: 0.0030 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9995 - val_loss: 0.0226 - val_output1_loss: 2.7004e-05 - val_output2_loss: 0.0021 - val_output3_loss: 6.5118e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "690/690 [==============================] - 3s 5ms/step - loss: 0.0255 - output1_loss: 3.7024e-05 - output2_loss: 0.0031 - output3_loss: 0.0027 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9997 - val_loss: 0.0214 - val_output1_loss: 2.1638e-05 - val_output2_loss: 0.0016 - val_output3_loss: 4.4712e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0253 - output1_loss: 3.3327e-05 - output2_loss: 0.0032 - output3_loss: 0.0027 - output1_accuracy: 1.0000 - output2_accuracy: 0.9997 - output3_accuracy: 0.9996 - val_loss: 0.0212 - val_output1_loss: 1.6874e-05 - val_output2_loss: 0.0013 - val_output3_loss: 5.1500e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0243 - output1_loss: 3.1269e-05 - output2_loss: 0.0027 - output3_loss: 0.0027 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9996 - val_loss: 0.0207 - val_output1_loss: 2.2507e-05 - val_output2_loss: 0.0017 - val_output3_loss: 3.3975e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0241 - output1_loss: 3.0356e-05 - output2_loss: 0.0028 - output3_loss: 0.0026 - output1_accuracy: 1.0000 - output2_accuracy: 0.9998 - output3_accuracy: 0.9996 - val_loss: 0.0202 - val_output1_loss: 1.3506e-05 - val_output2_loss: 0.0013 - val_output3_loss: 4.6237e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0238 - output1_loss: 2.9281e-05 - output2_loss: 0.0026 - output3_loss: 0.0028 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9995 - val_loss: 0.0197 - val_output1_loss: 2.0448e-05 - val_output2_loss: 0.0012 - val_output3_loss: 3.3447e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0230 - output1_loss: 2.7942e-05 - output2_loss: 0.0026 - output3_loss: 0.0024 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9996 - val_loss: 0.0192 - val_output1_loss: 2.4007e-05 - val_output2_loss: 0.0012 - val_output3_loss: 4.0590e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0225 - output1_loss: 2.6132e-05 - output2_loss: 0.0025 - output3_loss: 0.0024 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9997 - val_loss: 0.0200 - val_output1_loss: 2.8800e-05 - val_output2_loss: 0.0011 - val_output3_loss: 0.0013 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 0.9999\n",
      "Epoch 36/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0224 - output1_loss: 2.7473e-05 - output2_loss: 0.0025 - output3_loss: 0.0024 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9997 - val_loss: 0.0192 - val_output1_loss: 1.0903e-05 - val_output2_loss: 0.0015 - val_output3_loss: 4.5970e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0219 - output1_loss: 2.5009e-05 - output2_loss: 0.0024 - output3_loss: 0.0024 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9996 - val_loss: 0.0185 - val_output1_loss: 1.2039e-05 - val_output2_loss: 0.0011 - val_output3_loss: 6.2491e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0218 - output1_loss: 2.4717e-05 - output2_loss: 0.0024 - output3_loss: 0.0023 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9996 - val_loss: 0.0182 - val_output1_loss: 8.9684e-06 - val_output2_loss: 0.0012 - val_output3_loss: 3.9753e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0212 - output1_loss: 2.3523e-05 - output2_loss: 0.0025 - output3_loss: 0.0022 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9997 - val_loss: 0.0177 - val_output1_loss: 1.2420e-05 - val_output2_loss: 9.5713e-04 - val_output3_loss: 4.5839e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0211 - output1_loss: 2.3400e-05 - output2_loss: 0.0023 - output3_loss: 0.0025 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9996 - val_loss: 0.0176 - val_output1_loss: 1.1847e-05 - val_output2_loss: 8.9530e-04 - val_output3_loss: 6.4398e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0208 - output1_loss: 2.1756e-05 - output2_loss: 0.0024 - output3_loss: 0.0023 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9996 - val_loss: 0.0175 - val_output1_loss: 1.2841e-05 - val_output2_loss: 8.7943e-04 - val_output3_loss: 2.7320e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0199 - output1_loss: 2.1114e-05 - output2_loss: 0.0022 - output3_loss: 0.0020 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9997 - val_loss: 0.0170 - val_output1_loss: 8.8269e-06 - val_output2_loss: 8.0281e-04 - val_output3_loss: 2.5630e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0201 - output1_loss: 2.1472e-05 - output2_loss: 0.0021 - output3_loss: 0.0023 - output1_accuracy: 1.0000 - output2_accuracy: 1.0000 - output3_accuracy: 0.9996 - val_loss: 0.0168 - val_output1_loss: 2.0640e-05 - val_output2_loss: 0.0011 - val_output3_loss: 3.8321e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0199 - output1_loss: 2.1864e-05 - output2_loss: 0.0021 - output3_loss: 0.0021 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9996 - val_loss: 0.0168 - val_output1_loss: 8.8234e-06 - val_output2_loss: 0.0014 - val_output3_loss: 2.5179e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0194 - output1_loss: 2.0965e-05 - output2_loss: 0.0022 - output3_loss: 0.0021 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9997 - val_loss: 0.0162 - val_output1_loss: 1.0808e-05 - val_output2_loss: 8.3518e-04 - val_output3_loss: 2.9533e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0190 - output1_loss: 1.8779e-05 - output2_loss: 0.0020 - output3_loss: 0.0021 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9997 - val_loss: 0.0162 - val_output1_loss: 1.3677e-05 - val_output2_loss: 9.4011e-04 - val_output3_loss: 3.6240e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0188 - output1_loss: 2.0966e-05 - output2_loss: 0.0021 - output3_loss: 0.0020 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9998 - val_loss: 0.0158 - val_output1_loss: 3.8231e-06 - val_output2_loss: 7.5421e-04 - val_output3_loss: 3.8280e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0185 - output1_loss: 1.8204e-05 - output2_loss: 0.0020 - output3_loss: 0.0020 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9997 - val_loss: 0.0158 - val_output1_loss: 1.3373e-05 - val_output2_loss: 7.5125e-04 - val_output3_loss: 5.1599e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0184 - output1_loss: 1.8870e-05 - output2_loss: 0.0019 - output3_loss: 0.0021 - output1_accuracy: 1.0000 - output2_accuracy: 1.0000 - output3_accuracy: 0.9996 - val_loss: 0.0153 - val_output1_loss: 1.0279e-05 - val_output2_loss: 8.0361e-04 - val_output3_loss: 2.1501e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.0179 - output1_loss: 1.8464e-05 - output2_loss: 0.0019 - output3_loss: 0.0018 - output1_accuracy: 1.0000 - output2_accuracy: 0.9999 - output3_accuracy: 0.9997 - val_loss: 0.0154 - val_output1_loss: 6.9746e-06 - val_output2_loss: 7.4334e-04 - val_output3_loss: 4.7359e-04 - val_output1_accuracy: 1.0000 - val_output2_accuracy: 1.0000 - val_output3_accuracy: 1.0000\n",
      "Model saved as ed_49x49.keras\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0155 - output1_loss: 7.4219e-06 - output2_loss: 7.6095e-04 - output3_loss: 5.2125e-04 - output1_accuracy: 1.0000 - output2_accuracy: 1.0000 - output3_accuracy: 0.9999\n",
      "Test Results: [0.015481438487768173, 7.421853297273628e-06, 0.0007609495660290122, 0.0005212518735788763, 1.0, 1.0, 0.9999444484710693]\n",
      "1688/1688 [==============================] - 2s 1ms/step\n",
      "Confusion Matrix for Output 1:\n",
      "[[ 5875     0]\n",
      " [    0 48125]]\n",
      "Confusion Matrix for Output 2:\n",
      "[[ 5875     0     0     0     0]\n",
      " [    0 12004     0     0     0]\n",
      " [    0     0 11993     0     0]\n",
      " [    0     0     0 12007     0]\n",
      " [    0     0     0     0 12121]]\n",
      "Confusion Matrix for Output 3:\n",
      "[[ 2940     0     0     0     0]\n",
      " [    0 14912     0     0     0]\n",
      " [    0     0 12110     0     0]\n",
      " [    0     3     0 12109     0]\n",
      " [    0     0     0     0 11926]]\n",
      "Accuracy for Output 1: 1.0\n",
      "Accuracy for Output 2: 1.0\n",
      "Accuracy for Output 3: 0.9999444444444444\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data('C:\\Ankit\\Programs\\RP\\data\\\\train\\mat_7x7.csv')\n",
    "train_and_evaluate_multi_output_model(X_train, X_test, y_train, y_test, input_size=49)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c23ea-ffe4-44f6-991e-d4abdc7e5c2b",
   "metadata": {},
   "source": [
    "# Model Evaluation Summary\n",
    "\n",
    "The model architecture is evaluated under three configurations: **3x3**, **5x5**, and **7x7** input settings. Each configuration employs shared feature extraction layers and task-specific dense layers. The performance is measured for three outputs: Binary Classification (Output 1), Multiclass Classification with 4 classes (Output 2), and another Multiclass Classification with 4 classes (Output 3).\n",
    "\n",
    "---\n",
    "\n",
    "## **Model Configurations**\n",
    "\n",
    "### **3x3 Model**\n",
    "- **Inputs**: 9\n",
    "- **Hidden Units**: 9\n",
    "- **Dropout**: 0.3\n",
    "- **Epochs**: 50\n",
    "- **Learning Rate**: 0.001\n",
    "\n",
    "### **5x5 Model**\n",
    "- **Inputs**: 25\n",
    "- **Hidden Units**: 25\n",
    "- **Dropout**: 0.3\n",
    "- **Epochs**: 50\n",
    "- **Learning Rate**: 0.001\n",
    "\n",
    "### **7x7 Model**\n",
    "- **Inputs**: 49\n",
    "- **Hidden Units**: 48\n",
    "- **Dropout**: 0.3\n",
    "- **Epochs**: 50\n",
    "- **Learning Rate**: 0.001\n",
    "\n",
    "---\n",
    "\n",
    "## **Results**\n",
    "\n",
    "### **3x3 Model**\n",
    "\n",
    "- **Confusion Matrices**:\n",
    "\n",
    "  - **Output 1 (Binary Classification)**:\n",
    "    ```\n",
    "    [[ 4219     0]\n",
    "     [    0 33581]]\n",
    "    ```\n",
    "\n",
    "  - **Output 2 (Multiclass Classification with 4 classes)**:\n",
    "    ```\n",
    "    [[4219    0    0    0    0]\n",
    "     [   0 8447    0    0    1]\n",
    "     [   0    0 8333    2    0]\n",
    "     [   0    0    0 8399    0]\n",
    "     [   0    1    0    5 8393]]\n",
    "    ```\n",
    "\n",
    "  - **Output 3 (Multiclass Classification with 4 classes)**:\n",
    "    ```\n",
    "    [[ 2118     0     2     0     0]\n",
    "     [    0 10553     0     1     5]\n",
    "     [    0     1  8273     4     0]\n",
    "     [    0     0     4  8376     1]\n",
    "     [    0     1     0     0  8461]]\n",
    "    ```\n",
    "\n",
    "- **Accuracy**:\n",
    "  - **Output 1**: **1.0**\n",
    "  - **Output 2**: **0.999761**\n",
    "  - **Output 3**: **0.999497**\n",
    "\n",
    "---\n",
    "\n",
    "### **5x5 Model**\n",
    "\n",
    "- **Confusion Matrices**:\n",
    "\n",
    "  - **Output 1 (Binary Classification)**:\n",
    "    ```\n",
    "    [[ 4219     0]\n",
    "     [    0 33581]]\n",
    "    ```\n",
    "\n",
    "  - **Output 2 (Multiclass Classification with 4 classes)**:\n",
    "    ```\n",
    "    [[4219    0    0    0    0]\n",
    "     [   0 8448    0    0    0]\n",
    "     [   0    0 8335    0    0]\n",
    "     [   0    0    0 8399    0]\n",
    "     [   0    0    0    0 8399]]\n",
    "    ```\n",
    "\n",
    "  - **Output 3 (Multiclass Classification with 4 classes)**:\n",
    "    ```\n",
    "    [[ 2120     0     0     0     0]\n",
    "     [    0 10559     0     0     0]\n",
    "     [    0     0  8278     0     0]\n",
    "     [    0     0     0  8381     0]\n",
    "     [    0     0     0     0  8462]]\n",
    "    ```\n",
    "\n",
    "- **Accuracy**:\n",
    "  - **Output 1**: **1.0**\n",
    "  - **Output 2**: **1.0**\n",
    "  - **Output 3**: **1.0**\n",
    "\n",
    "---\n",
    "\n",
    "### **7x7 Model**\n",
    "\n",
    "- **Confusion Matrices**:\n",
    "\n",
    "  - **Output 1 (Binary Classification)**:\n",
    "    ```\n",
    "    [[ 4219     0]\n",
    "     [    0 33581]]\n",
    "    ```\n",
    "\n",
    "  - **Output 2 (Multiclass Classification with 4 classes)**:\n",
    "    ```\n",
    "    [[4219    0    0    0    0]\n",
    "     [   0 8448    0    0    0]\n",
    "     [   0    0 8335    0    0]\n",
    "     [   0    0    0 8399    0]\n",
    "     [   0    0    0    0 8399]]\n",
    "    ```\n",
    "\n",
    "  - **Output 3 (Multiclass Classification with 4 classes)**:\n",
    "    ```\n",
    "    [[ 2120     0     0     0     0]\n",
    "     [    0 10559     0     0     0]\n",
    "     [    0     0  8278     0     0]\n",
    "     [    0     0     0  8381     0]\n",
    "     [    0     0     0     0  8462]]\n",
    "    ```\n",
    "\n",
    "- **Accuracy**:\n",
    "  - **Output 1**: **1.0**\n",
    "  - **Output 2**: **1.0**\n",
    "  - **Output 3**: **1.0**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87123bf7-71cc-4fd2-beb8-3a228997626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for 3x3 matrices\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 9, 1)]               0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 9, 8)                 32        ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 9, 8)                 0         ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 72)                   0         ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 4)                    292       ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 4)                    292       ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 4)                    292       ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " output1 (Dense)             (None, 1)                    5         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " output2 (Dense)             (None, 5)                    25        ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " output3 (Dense)             (None, 5)                    25        ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 963 (3.76 KB)\n",
      "Trainable params: 963 (3.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "Model for 5x5 matrices\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 25, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 25, 8)                32        ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 25, 8)                0         ['conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 200)                  0         ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 4)                    804       ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 4)                    804       ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 4)                    804       ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " output1 (Dense)             (None, 1)                    5         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " output2 (Dense)             (None, 5)                    25        ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " output3 (Dense)             (None, 5)                    25        ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "Model for 7x7 matrices\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 49, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 49, 8)                32        ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 49, 8)                0         ['conv1d_2[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 392)                  0         ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 4)                    1572      ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 4)                    1572      ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 4)                    1572      ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " output1 (Dense)             (None, 1)                    5         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " output2 (Dense)             (None, 5)                    25        ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " output3 (Dense)             (None, 5)                    25        ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4803 (18.76 KB)\n",
      "Trainable params: 4803 (18.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model_3x3 = tf.keras.models.load_model(\"C:\\Ankit\\Programs\\RP\\models\\ed_9x9.keras\")\n",
    "model_5x5 = tf.keras.models.load_model(\"C:\\Ankit\\Programs\\RP\\models\\ed_25x25.keras\") \n",
    "model_7x7 = tf.keras.models.load_model(\"C:\\Ankit\\Programs\\RP\\models\\ed_49x49.keras\")\n",
    "print(\"Model for 3x3 matrices\")\n",
    "model_3x3.summary()\n",
    "print(\"\\n\")\n",
    "print(\"Model for 5x5 matrices\")\n",
    "model_5x5.summary()\n",
    "print(\"\\n\")\n",
    "print(\"Model for 7x7 matrices\")\n",
    "model_7x7.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66979982-0e8d-4372-97a2-f2a8c2c161ae",
   "metadata": {},
   "source": [
    "## Testing with custom inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "961df28b-a7ba-49ba-b682-f18a34757317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to add random noise to a matrix\n",
    "def add_noise(matrix, noise_level=30):\n",
    "    noisy_matrix = matrix + np.random.randint(-noise_level, noise_level + 1, matrix.shape)\n",
    "    noisy_matrix = np.clip(noisy_matrix, 0, 255)\n",
    "    return noisy_matrix\n",
    "\n",
    "#function to generate csv file for the matrices\n",
    "def generate_csv(matrices, noise_level, num_iterations, filename):\n",
    "    data = []\n",
    "    \n",
    "    for matrix_name, matrix in matrices.items():\n",
    "        base_matrix = np.array(matrix)\n",
    "        first_digit = int(matrix_name[-2])\n",
    "        second_digit = int(matrix_name[-1])\n",
    "        size = len(matrix[0])\n",
    "        \n",
    "        for _ in range(num_iterations):\n",
    "            # Add random noise\n",
    "            noisy_matrix = add_noise(base_matrix, noise_level)\n",
    "            # Normalise the matrix to\n",
    "            noisy_matrix = noisy_matrix / 255.0\n",
    "            \n",
    "            # Flatten the matrix to store as a row\n",
    "            noisy_matrix_flat = noisy_matrix.flatten()\n",
    "    \n",
    "            if first_digit == 0:\n",
    "                edge_detected = 0\n",
    "            else:\n",
    "                edge_detected = 1\n",
    "            \n",
    "            # Append the flattened matrix and labels to the data list\n",
    "            data.append(list(noisy_matrix_flat))\n",
    "    \n",
    "    # Convert the data to a DataFrame and save to CSV\n",
    "    columns = [f'pixel_{i}' for i in range(size*size)]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "    print(\"Custom CSV file generated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfd6a118-1d25-47bc-ab34-32f3e5e8212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Automatic testing from csv file\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to load custom input from CSV, make predictions, and print results\n",
    "def load_and_predict_from_csv(model_path, csv_path):\n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    \n",
    "    # Load custom input from CSV\n",
    "    custom_input = pd.read_csv(csv_path, header=0).values  # Read CSV as NumPy array\n",
    "    print(f\"Loaded input from {csv_path}:\\n{custom_input}\")\n",
    "    for csi in custom_input:\n",
    "    # Preprocess the input (flatten and reshape for Conv1D model)\n",
    "        csi = csi.flatten()  # Flatten the matrix into a 1D array\n",
    "        csi = csi.reshape(1, -1, 1)  # Reshape to (1, input_size, 1)\n",
    "    \n",
    "        # Make predictions\n",
    "        predictions = model.predict(csi)\n",
    "        \n",
    "        # Interpret predictions\n",
    "        has_edge = \"Yes\" if predictions[0][0] > 0.5 else \"No\"  # Binary output (threshold at 0.5)\n",
    "        edge_no1 = np.argmax(predictions[1], axis=1)[0]     \n",
    "        edge_no2 = np.argmax(predictions[2], axis=1)[0]     \n",
    "        \n",
    "        # Print output in desired format\n",
    "        print(f\"Has Edge: {has_edge}\")\n",
    "        print(f\"Edge no: {edge_no1}, {edge_no2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39bcd24e-4b0a-497e-86c9-c609fec26d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom CSV file generated successfully.\n",
      "Model loaded from C:\\Ankit\\Programs\\RP\\multi_output_model_9x9_smaller.keras\n",
      "Loaded input from custom_3x3_inputs.csv:\n",
      "[[0.         0.16470588 0.07058824 0.         0.31764706 0.12941176\n",
      "  0.01960784 0.12156863 0.20392157]\n",
      " [1.         1.         0.83529412 1.         1.         1.\n",
      "  0.79607843 1.         1.        ]\n",
      " [0.         0.         0.         0.         0.06666667 0.04313725\n",
      "  0.80784314 1.         1.        ]\n",
      " [1.         0.84705882 1.         0.05882353 0.25882353 0.\n",
      "  0.         0.36862745 0.        ]\n",
      " [0.83921569 0.7372549  1.         0.85098039 1.         1.\n",
      "  0.28235294 0.         0.        ]\n",
      " [0.         0.22745098 0.         0.74509804 0.99215686 0.92941176\n",
      "  1.         1.         0.7372549 ]\n",
      " [1.         0.90196078 0.         1.         0.17647059 0.\n",
      "  0.05882353 0.15294118 0.        ]\n",
      " [0.         0.         0.69019608 0.         0.97647059 1.\n",
      "  1.         1.         0.80784314]\n",
      " [0.25098039 0.15686275 0.         0.         0.         0.6745098\n",
      "  0.14117647 1.         0.60784314]\n",
      " [0.83137255 0.61960784 1.         0.78823529 0.6745098  0.28235294\n",
      "  1.         0.         0.        ]\n",
      " [0.87843137 0.         0.06666667 1.         0.         0.07058824\n",
      "  1.         0.         0.28235294]\n",
      " [0.         0.18431373 0.74901961 0.         0.         0.65490196\n",
      "  0.20392157 0.00392157 1.        ]\n",
      " [0.13333333 1.         0.85098039 0.         1.         0.74509804\n",
      "  0.         0.61176471 0.97647059]\n",
      " [1.         0.93333333 0.12941176 0.80784314 1.         0.\n",
      "  1.         0.80784314 0.        ]\n",
      " [0.63137255 0.20784314 0.         0.62745098 0.83921569 0.\n",
      "  0.99607843 0.96862745 0.95294118]\n",
      " [0.         1.         1.         0.09411765 0.02745098 1.\n",
      "  0.14117647 0.27058824 0.25490196]\n",
      " [0.82352941 0.97647059 0.82745098 0.14509804 0.90196078 1.\n",
      "  0.36862745 0.02352941 1.        ]\n",
      " [0.34117647 0.         0.12156863 0.79215686 0.         0.\n",
      "  1.         0.9254902  0.        ]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "Has Edge: No\n",
      "Edge no: 0, 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: No\n",
      "Edge no: 0, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 1, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 1, 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 1, 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 1, 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 2, 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 2, 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 4, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 4, 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 4, 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 4, 4\n"
     ]
    }
   ],
   "source": [
    "#3x3 test manual\n",
    "matrices = matrices3x3\n",
    "noise_level = 100\n",
    "num_iterations = 1\n",
    "filename = 'custom_3x3_inputs.csv'\n",
    "generate_csv(matrices, noise_level, num_iterations, filename)\n",
    "\n",
    "csv_path = 'custom_3x3_inputs.csv'\n",
    "model_path = 'C:\\Ankit\\Programs\\RP\\models\\ed_9x9.keras'\n",
    "load_and_predict_from_csv(model_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a309c1f2-8b89-4f6b-81a0-1b070d0f6a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom CSV file generated successfully.\n",
      "Model loaded from C:\\Ankit\\Programs\\RP\\multi_output_model_25x25_smaller.keras\n",
      "Loaded input from custom_5x5_inputs.csv:\n",
      "[[0.         0.03137255 0.         0.29803922 0.         0.23921569\n",
      "  0.2745098  0.23137255 0.21176471 0.         0.31372549 0.23921569\n",
      "  0.         0.30196078 0.         0.         0.21176471 0.34901961\n",
      "  0.23921569 0.2745098  0.         0.14901961 0.30588235 0.39215686\n",
      "  0.25490196]\n",
      " [0.72156863 1.         0.63921569 1.         0.75686275 1.\n",
      "  0.89803922 1.         0.85490196 1.         0.70980392 1.\n",
      "  0.89411765 0.61568627 0.96470588 0.80784314 1.         0.65098039\n",
      "  0.89411765 0.91372549 0.9372549  1.         0.63921569 0.95294118\n",
      "  1.        ]\n",
      " [0.         0.06666667 0.         0.         0.27843137 0.\n",
      "  0.03921569 0.         0.         0.         0.         0.21176471\n",
      "  0.         0.3372549  0.02745098 1.         1.         0.83137255\n",
      "  0.96078431 0.84705882 1.         1.         0.65882353 1.\n",
      "  1.        ]\n",
      " [1.         1.         0.67058824 1.         0.82352941 0.9372549\n",
      "  0.76470588 1.         1.         1.         0.29803922 0.00784314\n",
      "  0.         0.17254902 0.         0.01960784 0.         0.\n",
      "  0.         0.36862745 0.09019608 0.25098039 0.         0.05882353\n",
      "  0.        ]\n",
      " [0.97254902 0.82745098 1.         0.74509804 0.6745098  0.82745098\n",
      "  1.         0.89803922 0.80784314 1.         0.9254902  1.\n",
      "  0.84705882 0.62352941 1.         0.10980392 0.         0.\n",
      "  0.12156863 0.         0.         0.         0.37647059 0.\n",
      "  0.        ]\n",
      " [0.03137255 0.2745098  0.         0.         0.         0.00392157\n",
      "  0.         0.25098039 0.06666667 0.         1.         0.98823529\n",
      "  0.77254902 1.         1.         0.85882353 1.         0.75294118\n",
      "  0.75294118 0.70588235 0.65490196 0.90980392 0.8745098  1.\n",
      "  0.70980392]\n",
      " [0.36470588 0.13333333 0.12941176 0.29803922 1.         0.\n",
      "  0.         0.17647059 1.         0.69803922 0.12156863 0.\n",
      "  0.95294118 1.         1.         0.         0.69019608 0.79215686\n",
      "  1.         0.91764706 1.         1.         0.94117647 1.\n",
      "  0.81960784]\n",
      " [1.         0.91764706 0.61176471 1.         0.05882353 1.\n",
      "  0.97254902 0.73333333 0.10980392 0.09019608 0.70980392 0.74509804\n",
      "  0.         0.         0.34117647 0.72156863 0.14509804 0.16470588\n",
      "  0.05098039 0.16078431 0.         0.         0.         0.\n",
      "  0.36862745]\n",
      " [0.21960784 0.         0.23529412 0.         0.16470588 0.02352941\n",
      "  0.         0.         0.09019608 1.         0.         0.16470588\n",
      "  0.16470588 1.         1.         0.29019608 0.29411765 1.\n",
      "  0.99215686 1.         0.         0.99215686 1.         1.\n",
      "  1.        ]\n",
      " [1.         1.         0.94509804 0.70980392 0.84313725 0.98039216\n",
      "  1.         0.73333333 1.         0.         0.63921569 1.\n",
      "  1.         0.         0.         1.         0.62352941 0.14509804\n",
      "  0.32156863 0.         1.         0.09411765 0.         0.\n",
      "  0.        ]\n",
      " [0.18039216 0.06666667 0.23529412 1.         1.         0.24705882\n",
      "  0.         0.         0.86666667 1.         0.         0.\n",
      "  0.         1.         0.67843137 0.         0.06666667 0.\n",
      "  0.60784314 1.         0.0627451  0.         0.1372549  1.\n",
      "  0.96078431]\n",
      " [1.         1.         0.90196078 0.2        0.27058824 0.67058824\n",
      "  1.         1.         0.         0.         0.61960784 1.\n",
      "  1.         0.         0.         1.         1.         1.\n",
      "  0.         0.         0.83529412 0.8745098  1.         0.\n",
      "  0.25882353]\n",
      " [0.31372549 0.         1.         1.         1.         0.\n",
      "  0.36078431 0.89411765 1.         1.         0.01176471 0.19215686\n",
      "  1.         0.89019608 1.         0.10980392 0.         1.\n",
      "  1.         0.77647059 0.33333333 0.         0.91372549 0.62745098\n",
      "  0.85490196]\n",
      " [1.         1.         0.32941176 0.         0.         0.80392157\n",
      "  0.80784314 0.14901961 0.         0.         0.82352941 0.64705882\n",
      "  0.25098039 0.08235294 0.         0.65882353 0.99607843 0.\n",
      "  0.         0.07058824 1.         0.61960784 0.10588235 0.\n",
      "  0.        ]\n",
      " [0.83529412 0.         0.         0.05490196 0.         0.65490196\n",
      "  0.67058824 0.         0.3254902  0.21960784 0.63921569 0.82352941\n",
      "  0.90588235 0.30980392 0.         0.95294118 1.         0.64705882\n",
      "  0.70588235 0.         0.64705882 0.63921569 1.         0.97647059\n",
      "  1.        ]\n",
      " [0.27058824 0.83529412 0.96470588 0.99215686 0.61176471 0.18431373\n",
      "  0.         0.96078431 0.99607843 1.         0.         0.03529412\n",
      "  0.30588235 0.78431373 1.         0.34901961 0.         0.1372549\n",
      "  0.         1.         0.         0.         0.21176471 0.01960784\n",
      "  0.        ]\n",
      " [0.21960784 0.34509804 0.25882353 0.32941176 0.2745098  1.\n",
      "  0.         0.         0.22352941 0.         0.8745098  1.\n",
      "  0.10196078 0.         0.         0.7254902  0.94509804 1.\n",
      "  0.         0.36470588 0.85490196 1.         1.         1.\n",
      "  0.06666667]\n",
      " [1.         1.         0.71372549 1.         1.         0.\n",
      "  0.74509804 1.         0.90980392 0.90196078 0.         0.30588235\n",
      "  0.84313725 1.         1.         0.         0.17647059 0.18823529\n",
      "  0.8627451  1.         0.16470588 0.         0.         0.\n",
      "  1.        ]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "Has Edge: No\n",
      "Edge no: 0, 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Has Edge: No\n",
      "Edge no: 0, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 1, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 1, 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 1, 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 1, 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 2, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 2, 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 2, 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 2, 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 4, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 4, 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 4, 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 4, 4\n"
     ]
    }
   ],
   "source": [
    "#5x5 test manual\n",
    "matrices = matrices5x5\n",
    "noise_level = 100\n",
    "num_iterations = 1\n",
    "filename = 'custom_5x5_inputs.csv'\n",
    "generate_csv(matrices, noise_level, num_iterations, filename)\n",
    "\n",
    "csv_path = 'custom_5x5_inputs.csv'\n",
    "model_path = 'C:\\Ankit\\Programs\\RP\\models\\ed_25x25.keras'\n",
    "load_and_predict_from_csv(model_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "509170dd-be1c-4413-bf57-9a7ece9549ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom CSV file generated successfully.\n",
      "Model loaded from C:\\Ankit\\Programs\\RP\\multi_output_model_49x49_smaller.keras\n",
      "Loaded input from custom_7x7_inputs.csv:\n",
      "[[0.31764706 0.18431373 0.22745098 0.17647059 0.05098039 0.0627451\n",
      "  0.18823529 0.         0.28235294 0.         0.         0.\n",
      "  0.36470588 0.01568627 0.         0.29411765 0.10196078 0.\n",
      "  0.         0.2627451  0.         0.07058824 0.22745098 0.21568627\n",
      "  0.09411765 0.         0.         0.         0.10980392 0.01568627\n",
      "  0.23921569 0.26666667 0.         0.         0.19607843 0.10980392\n",
      "  0.         0.34509804 0.16078431 0.30980392 0.         0.\n",
      "  0.         0.         0.         0.         0.12156863 0.18431373\n",
      "  0.3254902 ]\n",
      " [1.         1.         1.         1.         0.77254902 1.\n",
      "  0.73333333 0.99607843 1.         1.         1.         1.\n",
      "  0.82745098 0.84705882 1.         1.         0.89019608 0.79607843\n",
      "  0.83921569 0.77647059 1.         1.         1.         0.82352941\n",
      "  0.9372549  0.98823529 1.         0.96862745 0.96862745 0.96862745\n",
      "  0.90588235 0.66666667 0.77254902 1.         0.65882353 1.\n",
      "  0.81568627 0.8        1.         1.         0.86666667 0.91764706\n",
      "  0.81960784 0.63921569 1.         1.         1.         1.\n",
      "  1.        ]\n",
      " [0.02745098 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.02352941 0.21960784\n",
      "  0.03921569 0.05098039 0.22352941 0.31372549 0.         0.01176471\n",
      "  0.         0.18823529 0.         0.26666667 0.1254902  0.\n",
      "  0.07058824 0.         0.28627451 0.         1.         1.\n",
      "  1.         0.61960784 0.6627451  1.         1.         0.74117647\n",
      "  0.78823529 1.         0.99607843 1.         0.70196078 1.\n",
      "  1.         0.61960784 1.         1.         0.90588235 0.7372549\n",
      "  0.85882353]\n",
      " [0.97647059 0.85882353 0.83529412 0.71764706 1.         1.\n",
      "  1.         0.71372549 0.75686275 1.         1.         1.\n",
      "  0.80392157 1.         0.6627451  1.         0.80392157 1.\n",
      "  0.99607843 1.         0.68235294 0.         0.         0.\n",
      "  0.         0.         0.2        0.14509804 0.         0.\n",
      "  0.16862745 0.27058824 0.         0.         0.23921569 0.18823529\n",
      "  0.         0.         0.         0.29803922 0.06666667 0.22352941\n",
      "  0.21176471 0.         0.18431373 0.         0.21176471 0.25882353\n",
      "  0.        ]\n",
      " [1.         1.         0.69411765 1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  0.95686275 1.         0.69411765 0.90980392 1.         0.63921569\n",
      "  1.         1.         1.         1.         1.         0.83529412\n",
      "  1.         1.         1.         1.         0.         0.21960784\n",
      "  0.         0.         0.15686275 0.34509804 0.14901961 0.21176471\n",
      "  0.         0.         0.1254902  0.         0.         0.\n",
      "  0.3372549  0.         0.         0.         0.27058824 0.14901961\n",
      "  0.27058824]\n",
      " [0.15294118 0.15294118 0.         0.17647059 0.         0.\n",
      "  0.         0.35686275 0.         0.31764706 0.         0.\n",
      "  0.24705882 0.21960784 0.         0.         0.         0.0745098\n",
      "  0.24313725 0.         0.09803922 0.72941176 0.85490196 1.\n",
      "  1.         1.         0.98039216 0.80392157 0.97647059 0.76862745\n",
      "  1.         0.71764706 1.         1.         1.         0.60784314\n",
      "  1.         1.         0.94901961 1.         0.74901961 0.94117647\n",
      "  0.94117647 1.         0.78823529 0.65098039 0.85098039 0.62352941\n",
      "  1.        ]\n",
      " [0.         0.37647059 0.05490196 0.         0.         0.\n",
      "  1.         0.         0.06666667 0.21176471 0.         0.\n",
      "  0.95294118 0.98431373 0.10588235 0.         0.12941176 0.\n",
      "  0.63137255 1.         0.81960784 0.         0.12156863 0.\n",
      "  1.         1.         1.         1.         0.05098039 0.\n",
      "  1.         0.76078431 0.73333333 1.         0.91764706 0.\n",
      "  1.         0.65490196 1.         1.         0.7372549  1.\n",
      "  0.90588235 1.         1.         1.         1.         0.81960784\n",
      "  0.98431373]\n",
      " [1.         0.6745098  1.         0.75686275 0.74901961 0.90196078\n",
      "  0.32941176 1.         1.         1.         1.         0.77647059\n",
      "  0.25490196 0.25490196 0.89019608 1.         1.         1.\n",
      "  0.31372549 0.         0.25098039 1.         0.8745098  0.76078431\n",
      "  0.         0.10588235 0.         0.         1.         0.85490196\n",
      "  0.08235294 0.         0.         0.         0.         0.62352941\n",
      "  0.24313725 0.         0.         0.38039216 0.         0.\n",
      "  0.32941176 0.14901961 0.34117647 0.11372549 0.00784314 0.\n",
      "  0.3254902 ]\n",
      " [0.         0.         0.         0.         0.32941176 0.\n",
      "  0.         0.34509804 0.         0.         0.         0.\n",
      "  0.13333333 0.95294118 0.         0.         0.3372549  0.\n",
      "  0.         0.75294118 0.94901961 0.         0.05490196 0.35686275\n",
      "  0.         0.63921569 0.94901961 1.         0.         0.16078431\n",
      "  0.33333333 1.         0.84705882 1.         0.9254902  0.13333333\n",
      "  0.         1.         0.87843137 1.         0.99215686 0.84313725\n",
      "  0.01176471 0.82352941 0.80784314 1.         0.96078431 0.99607843\n",
      "  0.80784314]\n",
      " [0.85490196 0.78823529 0.80392157 0.69411765 1.         1.\n",
      "  1.         1.         0.83529412 1.         0.84313725 1.\n",
      "  0.72941176 0.         0.79607843 1.         1.         1.\n",
      "  0.79607843 0.         0.25882353 1.         0.85882353 0.90196078\n",
      "  1.         0.         0.         0.         0.96862745 0.96470588\n",
      "  1.         0.         0.32156863 0.20392157 0.         0.9372549\n",
      "  1.         0.         0.         0.12156863 0.         0.05882353\n",
      "  1.         0.31764706 0.         0.         0.09803922 0.25098039\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.92941176 1.\n",
      "  0.61176471 0.30980392 0.2745098  0.37647059 0.24705882 0.88235294\n",
      "  0.99215686 1.         0.         0.         0.25882353 0.\n",
      "  1.         1.         1.         0.21960784 0.29803922 0.05882353\n",
      "  0.         0.75686275 0.8        1.         0.         0.25882353\n",
      "  0.         0.         1.         1.         1.         0.\n",
      "  0.         0.22745098 0.25490196 0.97254902 1.         0.82352941\n",
      "  0.31372549 0.37647059 0.         0.         0.8745098  0.64313725\n",
      "  1.        ]\n",
      " [1.         1.         0.61176471 1.         0.0745098  0.33333333\n",
      "  0.23529412 1.         1.         1.         0.80784314 0.\n",
      "  0.         0.04705882 1.         0.67058824 1.         0.61176471\n",
      "  0.03921569 0.23137255 0.         1.         0.88235294 0.98823529\n",
      "  1.         0.         0.         0.         0.68627451 1.\n",
      "  1.         1.         0.         0.         0.         0.9254902\n",
      "  1.         1.         0.80784314 0.14117647 0.32156863 0.\n",
      "  1.         0.75294118 0.9254902  0.81568627 0.         0.\n",
      "  0.18039216]\n",
      " [0.         0.         0.         0.90980392 1.         0.77647059\n",
      "  0.84705882 0.         0.         0.         0.98823529 0.89411765\n",
      "  0.9254902  0.90588235 0.         0.27843137 0.         1.\n",
      "  0.90980392 0.90196078 0.70196078 0.08627451 0.         0.\n",
      "  1.         0.68627451 1.         1.         0.2745098  0.11764706\n",
      "  0.29019608 1.         0.98039216 0.8745098  1.         0.03137255\n",
      "  0.         0.30980392 1.         1.         0.74509804 0.76862745\n",
      "  0.         0.         0.27843137 1.         0.76470588 0.92156863\n",
      "  1.        ]\n",
      " [0.67843137 0.69411765 1.         0.38823529 0.         0.16078431\n",
      "  0.19215686 0.65490196 0.80784314 0.63529412 0.         0.\n",
      "  0.26666667 0.05490196 0.79607843 0.66666667 1.         0.\n",
      "  0.23137255 0.04705882 0.         1.         1.         1.\n",
      "  0.         0.00784314 0.38823529 0.00784314 0.94901961 1.\n",
      "  1.         0.23921569 0.         0.1372549  0.02745098 0.74117647\n",
      "  1.         1.         0.08235294 0.29019608 0.37647059 0.22745098\n",
      "  1.         1.         1.         0.30980392 0.         0.27058824\n",
      "  0.        ]\n",
      " [0.90980392 0.29803922 0.38823529 0.27058824 0.         0.0745098\n",
      "  0.         0.94509804 0.63921569 0.         0.         0.36862745\n",
      "  0.         0.         1.         0.92941176 1.         0.\n",
      "  0.13333333 0.         0.         1.         0.89411765 1.\n",
      "  0.90980392 0.39215686 0.26666667 0.         0.74117647 1.\n",
      "  0.87058824 0.60784314 1.         0.         0.         0.96078431\n",
      "  1.         0.74901961 1.         0.84313725 1.         0.06666667\n",
      "  0.75294118 1.         0.77254902 0.63529412 1.         0.67058824\n",
      "  1.        ]\n",
      " [0.13333333 0.92156863 0.82352941 0.9254902  0.82352941 1.\n",
      "  0.67058824 0.         0.32156863 1.         0.71764706 0.62745098\n",
      "  1.         0.81960784 0.         0.02352941 0.         1.\n",
      "  1.         0.90980392 0.67843137 0.38431373 0.         0.\n",
      "  0.         1.         0.60784314 0.95686275 0.08235294 0.29803922\n",
      "  0.         0.23137255 0.         0.63137255 0.67843137 0.05098039\n",
      "  0.09803922 0.18039216 0.29411765 0.         0.         1.\n",
      "  0.         0.23137255 0.10980392 0.         0.         0.26666667\n",
      "  0.2627451 ]\n",
      " [0.         0.23921569 0.         0.3372549  0.19607843 0.\n",
      "  0.         1.         0.         0.00392157 0.         0.\n",
      "  0.08627451 0.25098039 0.83921569 1.         0.         0.\n",
      "  0.36078431 0.         0.         0.96470588 0.83529412 1.\n",
      "  0.         0.         0.18039216 0.         0.96078431 0.65098039\n",
      "  0.74901961 0.97647059 0.19215686 0.         0.08627451 0.90196078\n",
      "  0.85490196 0.73333333 0.68627451 1.         0.35294118 0.1372549\n",
      "  1.         1.         1.         0.83921569 0.78431373 0.88235294\n",
      "  0.        ]\n",
      " [1.         0.95686275 1.         0.8627451  0.78431373 0.94509804\n",
      "  0.70196078 0.         1.         1.         0.72156863 1.\n",
      "  1.         1.         0.11372549 0.23529412 0.79215686 1.\n",
      "  1.         1.         0.83529412 0.34117647 0.         0.\n",
      "  1.         1.         1.         1.         0.23529412 0.15686275\n",
      "  0.         0.23529412 1.         1.         1.         0.19607843\n",
      "  0.02745098 0.03529412 0.3372549  0.23529412 0.98823529 0.85882353\n",
      "  0.         0.         0.         0.         0.02352941 0.36862745\n",
      "  0.96862745]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "Has Edge: No\n",
      "Edge no: 0, 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Has Edge: No\n",
      "Edge no: 0, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 1, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 1, 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 1, 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 1, 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 2, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 2, 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 2, 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 2, 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 3, 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 4, 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 4, 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 4, 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Has Edge: Yes\n",
      "Edge no: 4, 4\n"
     ]
    }
   ],
   "source": [
    "#7x7 test manual\n",
    "matrices = matrices7x7\n",
    "noise_level = 100\n",
    "num_iterations = 1\n",
    "filename = 'custom_7x7_inputs.csv'\n",
    "generate_csv(matrices, noise_level, num_iterations, filename)\n",
    "\n",
    "csv_path = 'custom_7x7_inputs.csv'\n",
    "model_path = 'C:\\Ankit\\Programs\\RP\\models\\ed_49x49.keras'\n",
    "load_and_predict_from_csv(model_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff61c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f7570-f358-48bd-98ed-e7cb2fcfdb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888dda6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
